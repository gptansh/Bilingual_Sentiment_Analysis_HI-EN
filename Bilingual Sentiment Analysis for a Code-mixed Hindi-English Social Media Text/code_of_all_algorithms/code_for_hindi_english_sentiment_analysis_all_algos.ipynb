{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "# from gensim.models import Word2Vec\n",
    "# import gensim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, getopt, csv, sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "import itertools\n",
    "from textblob import TextBlob\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\Hindi-English\\Hindi_english.csv\", encoding='latin-1', engine='python' )\n",
    "data['Text'] = data['Text'].str.lower()\n",
    "data['Text'] = data['Text'].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####STOPWORDS############\n",
    "stopwords = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\Hindi-English\\stopwords.csv\")\n",
    "stopwords = stopwords['Vocabulary'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Text'] = data['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\Hindi-English\\Hindi_Eng_vocab.csv\")\n",
    "vocabulary['Vocabulary'] = vocabulary['Vocabulary'].str.lower()\n",
    "vocabulary['Generalised Spelling'] = vocabulary['Generalised Spelling'].str.lower()\n",
    "voc_to_be_used = dict(zip(vocabulary['Vocabulary'], vocabulary['Generalised Spelling']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Text\"] = data[\"Text\"].str.replace('[^\\w\\s]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2 = {r'(\\b){}(\\b)'.format(k):r'\\1{}\\2'.format(v) for k,v in voc_to_be_used.items()}\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "# df = pd.DataFrame({'sentences': ['This is a very good site. I will recommend it to others.', 'Can you please give me a call at 9983938428. have issues with the listings.', 'good work! keep it up']})\n",
    "data['tokenized_sents'] = data.apply(lambda row: nltk.word_tokenize(row['Text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacement_dict = {r'(\\b){}(\\b)'.format(k):r'\\1{}\\2'.format(v) for k,v in voc_to_be_used.items()}\n",
    "# data['Text'] = data['Text'].replace(d2, regex=True)\n",
    "for sub in data['tokenized_sents']:\n",
    "    for i, word in enumerate(sub):\n",
    "        if word in voc_to_be_used:\n",
    "            sub[i] = voc_to_be_used[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "toekn_to_sentence = []\n",
    "# for token in list(data['tokenized_sents']):\n",
    "#     toekn_to_sentence.append([' '.join(i) for i in token])\n",
    "toekn_to_sentence.append([[' '.join(i)] for i in list(data['tokenized_sents'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_list = []\n",
    "for i in range(len(toekn_to_sentence[0])):\n",
    "    final_list.append(toekn_to_sentence[0][i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Token_to_sentence'] = final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tokenized_sents</th>\n",
       "      <th>Token_to_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coach dismissed nhi big jeetenge nhi</td>\n",
       "      <td>0</td>\n",
       "      <td>[coach, dismiss, nhi, big, jeetenge, nhi]</td>\n",
       "      <td>coach dismiss nhi big jeetenge nhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kewal bhagao team jeetne dhanyawad</td>\n",
       "      <td>0</td>\n",
       "      <td>[kewal, bhag, team, jeetna, dhanyavad]</td>\n",
       "      <td>kewal bhag team jeetna dhanyavad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>run media baate media villen esliye kamini med...</td>\n",
       "      <td>0</td>\n",
       "      <td>[run, media, baat, media, villain, isliye, kam...</td>\n",
       "      <td>run media baat media villain isliye kamine med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>devs innings won masterpiece</td>\n",
       "      <td>2</td>\n",
       "      <td>[devs, innings, won, masterpiece]</td>\n",
       "      <td>devs innings won masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhot nice lot respect heart</td>\n",
       "      <td>2</td>\n",
       "      <td>[bahut, nice, lot, respect, heart]</td>\n",
       "      <td>bahut nice lot respect heart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment  \\\n",
       "0               coach dismissed nhi big jeetenge nhi          0   \n",
       "1                 kewal bhagao team jeetne dhanyawad          0   \n",
       "2  run media baate media villen esliye kamini med...          0   \n",
       "3                       devs innings won masterpiece          2   \n",
       "4                        bhot nice lot respect heart          2   \n",
       "\n",
       "                                     tokenized_sents  \\\n",
       "0          [coach, dismiss, nhi, big, jeetenge, nhi]   \n",
       "1             [kewal, bhag, team, jeetna, dhanyavad]   \n",
       "2  [run, media, baat, media, villain, isliye, kam...   \n",
       "3                  [devs, innings, won, masterpiece]   \n",
       "4                 [bahut, nice, lot, respect, heart]   \n",
       "\n",
       "                                   Token_to_sentence  \n",
       "0                 coach dismiss nhi big jeetenge nhi  \n",
       "1                   kewal bhag team jeetna dhanyavad  \n",
       "2  run media baat media villain isliye kamine med...  \n",
       "3                       devs innings won masterpiece  \n",
       "4                       bahut nice lot respect heart  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Text', 'tokenized_sents'], axis = 1, inplace=True)\n",
    "data.rename(columns={'Token_to_sentence': 'Text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "for i in range(len(data)):\n",
    "    data['Text'][i] = ''.join(''.join(s)[:2] for _, s in itertools.groupby(data['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>coach dismiss nhi big jeetenge nhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>kewal bhag team jeetna dhanyavad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>run media baat media villain isliye kamine med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>devs innings won masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>bahut nice lot respect heart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          0                 coach dismiss nhi big jeetenge nhi\n",
       "1          0                   kewal bhag team jeetna dhanyavad\n",
       "2          0  run media baat media villain isliye kamine med...\n",
       "3          2                       devs innings won masterpiece\n",
       "4          2                       bahut nice lot respect heart"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "def tokens(message):\n",
    "#     message = unicode(message, 'utf8')\n",
    "    return TextBlob(message).words\n",
    "\n",
    "def lemmas(message):\n",
    "#     message = unicode(message, 'utf8').lower()\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide data into Test and Train\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(data['Text'], data['Sentiment'], test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('tfidf', TfidfTransformer()),('classifier', MultinomialNB())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__alpha': [1, 1e-1, 1e-2, 1e-3]\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "nb_detector = grid.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[205  30  41]\n",
      " [ 49  74  70]\n",
      " [ 47  25 206]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.74      0.71       276\n",
      "           1       0.57      0.38      0.46       193\n",
      "           2       0.65      0.74      0.69       278\n",
      "\n",
      "    accuracy                           0.65       747\n",
      "   macro avg       0.63      0.62      0.62       747\n",
      "weighted avg       0.64      0.65      0.64       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, nb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, nb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas)),('tfidf', TfidfTransformer()),('classifier', MultinomialNB())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__alpha': [1, 1e-1, 1e-2, 1e-3]\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "nb_detector = grid.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  13  18]\n",
      " [ 75  33  37]\n",
      " [ 35   9 194]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       270\n",
      "           1       0.60      0.23      0.33       145\n",
      "           2       0.78      0.82      0.80       238\n",
      "\n",
      "    accuracy                           0.71       653\n",
      "   macro avg       0.69      0.64      0.63       653\n",
      "weighted avg       0.70      0.71      0.68       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, nb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, nb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uni-Bi\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,2))),('tfidf', TfidfTransformer()),('classifier', MultinomialNB())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__alpha': [1, 1e-1, 1e-2, 1e-3]\n",
    "}\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "nb_detector = grid.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[239  13  18]\n",
      " [ 75  33  37]\n",
      " [ 35   9 194]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.89      0.77       270\n",
      "           1       0.60      0.23      0.33       145\n",
      "           2       0.78      0.82      0.80       238\n",
      "\n",
      "    accuracy                           0.71       653\n",
      "   macro avg       0.69      0.64      0.63       653\n",
      "weighted avg       0.70      0.71      0.68       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, nb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, nb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################SUPPORT VECTOR MACHINES##########################################################\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('tfidf', TfidfTransformer()),('classifier', SVC())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = [\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf', 'linear']},\n",
    "]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "svc_detector = grid.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191  55  30]\n",
      " [ 37 115  41]\n",
      " [ 42  59 177]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.69      0.70       276\n",
      "           1       0.50      0.60      0.55       193\n",
      "           2       0.71      0.64      0.67       278\n",
      "\n",
      "    accuracy                           0.65       747\n",
      "   macro avg       0.64      0.64      0.64       747\n",
      "weighted avg       0.66      0.65      0.65       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, svc_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, svc_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226  22  22]\n",
      " [ 59  52  34]\n",
      " [ 29  20 189]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       270\n",
      "           1       0.55      0.36      0.44       145\n",
      "           2       0.77      0.79      0.78       238\n",
      "\n",
      "    accuracy                           0.72       653\n",
      "   macro avg       0.68      0.66      0.66       653\n",
      "weighted avg       0.70      0.72      0.70       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uni-bi\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,2))),('tfidf', TfidfTransformer()),('classifier', SVC())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = [\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf', 'linear']},\n",
    "]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "svc_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "print (confusion_matrix(label_test, svc_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, svc_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226  22  22]\n",
      " [ 59  52  34]\n",
      " [ 29  20 189]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.77       270\n",
      "           1       0.55      0.36      0.44       145\n",
      "           2       0.77      0.79      0.78       238\n",
      "\n",
      "    accuracy                           0.72       653\n",
      "   macro avg       0.68      0.66      0.66       653\n",
      "weighted avg       0.70      0.72      0.70       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uni\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas)),('tfidf', TfidfTransformer()),('classifier', SVC())])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = [\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__kernel': ['linear']},\n",
    "        {'classifier__C': [1, 10, 100, 1000], 'classifier__gamma': [0.001, 0.0001], 'classifier__kernel': ['rbf', 'linear']},\n",
    "]\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "svc_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "print (confusion_matrix(label_test, svc_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, svc_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############SGC CLassifier##################################\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('tfidf', TfidfTransformer()),('classifier', SGDClassifier(max_iter=1000))])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__loss': [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "\"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "'classifier__penalty' : [\"l2\", \"l1\", \"none\"]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "sgd_detector = grid.fit(msg_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  50  26]\n",
      " [ 36 110  47]\n",
      " [ 41  54 183]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.72      0.72       276\n",
      "           1       0.51      0.57      0.54       193\n",
      "           2       0.71      0.66      0.69       278\n",
      "\n",
      "    accuracy                           0.66       747\n",
      "   macro avg       0.65      0.65      0.65       747\n",
      "weighted avg       0.67      0.66      0.66       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(label_test, sgd_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, sgd_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[227  21  22]\n",
      " [ 50  52  43]\n",
      " [ 24  20 194]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.80       270\n",
      "           1       0.56      0.36      0.44       145\n",
      "           2       0.75      0.82      0.78       238\n",
      "\n",
      "    accuracy                           0.72       653\n",
      "   macro avg       0.69      0.67      0.67       653\n",
      "weighted avg       0.71      0.72      0.71       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uni-Bi\n",
    "#############SGC CLassifier##################################\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,2))),('tfidf', TfidfTransformer()),('classifier', SGDClassifier(max_iter=1000))])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__loss': [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "\"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "'classifier__penalty' : [\"l2\", \"l1\", \"none\"]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "sgd_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "print (confusion_matrix(label_test, sgd_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, sgd_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[226  21  23]\n",
      " [ 56  48  41]\n",
      " [ 29  16 193]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.84      0.78       270\n",
      "           1       0.56      0.33      0.42       145\n",
      "           2       0.75      0.81      0.78       238\n",
      "\n",
      "    accuracy                           0.72       653\n",
      "   macro avg       0.68      0.66      0.66       653\n",
      "weighted avg       0.70      0.72      0.70       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Uni\n",
    "#############SGC CLassifier##################################\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas)),('tfidf', TfidfTransformer()),('classifier', SGDClassifier(max_iter=1000))])\n",
    "# pipeline parameters to automatically explore and tune\n",
    "# params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
    "params = {\n",
    "'tfidf__use_idf': (True, False),\n",
    "'bow__analyzer': (lemmas, tokens),\n",
    "'tfidf__norm': ('l1', 'l2'),\n",
    "'classifier__loss': [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n",
    "\"classifier__alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "'classifier__penalty' : [\"l2\", \"l1\", \"none\"]\n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "sgd_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "print (confusion_matrix(label_test, sgd_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, sgd_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6498 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "##########################LSTM IMPLEMENTATION##############################\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "#LSTM Implementation\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 14000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(data['Text'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (4979, 250)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(data['Text'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>coach dismiss nhi big jeetenge nhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>kewal bhag team jeetna dhanyavad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>run media baat media villain isliye kamine med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>devs innings won masterpiece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>bahut nice lot respect heart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sentiment                                               Text\n",
       "0          0                 coach dismiss nhi big jeetenge nhi\n",
       "1          0                   kewal bhag team jeetna dhanyavad\n",
       "2          0  run media baat media villain isliye kamine med...\n",
       "3          2                       devs innings won masterpiece\n",
       "4          2                       bahut nice lot respect heart"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (4979, 3)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['Sentiment']).values\n",
    "print('Shape of label tensor:', Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4481, 250) (4481, 3)\n",
      "(498, 250) (498, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.10, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 250, 100)          1400000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 13)                1313      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 42        \n",
      "=================================================================\n",
      "Total params: 1,481,755\n",
      "Trainable params: 1,481,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# variables_for_classification=3 #change it as per your number of categories\n",
    "model = Sequential()\n",
    "# model.add(Dense(variables_for_classification, activation='softmax'))\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(13, activation='softmax'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4032 samples, validate on 449 samples\n",
      "Epoch 1/100\n",
      "4032/4032 [==============================] - 192s 48ms/step - loss: 1.0932 - accuracy: 0.3743 - val_loss: 1.0686 - val_accuracy: 0.4410\n",
      "Epoch 2/100\n",
      "4032/4032 [==============================] - 188s 47ms/step - loss: 1.0161 - accuracy: 0.5119 - val_loss: 0.9720 - val_accuracy: 0.5390\n",
      "Epoch 3/100\n",
      "4032/4032 [==============================] - 183s 45ms/step - loss: 0.9075 - accuracy: 0.6248 - val_loss: 0.9435 - val_accuracy: 0.6125\n",
      "Epoch 4/100\n",
      "4032/4032 [==============================] - 40s 10ms/step - loss: 0.8032 - accuracy: 0.7393 - val_loss: 0.9013 - val_accuracy: 0.6370\n",
      "Epoch 5/100\n",
      "4032/4032 [==============================] - 38s 9ms/step - loss: 0.7046 - accuracy: 0.8073 - val_loss: 0.9098 - val_accuracy: 0.6169\n",
      "Epoch 6/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.6208 - accuracy: 0.8522 - val_loss: 0.9001 - val_accuracy: 0.6169\n",
      "Epoch 7/100\n",
      "4032/4032 [==============================] - 35s 9ms/step - loss: 0.6094 - accuracy: 0.8363 - val_loss: 0.9202 - val_accuracy: 0.6036\n",
      "Epoch 8/100\n",
      "4032/4032 [==============================] - 42s 10ms/step - loss: 0.5256 - accuracy: 0.8817 - val_loss: 0.9209 - val_accuracy: 0.6169\n",
      "Epoch 9/100\n",
      "4032/4032 [==============================] - 42s 11ms/step - loss: 0.4845 - accuracy: 0.8934 - val_loss: 0.9250 - val_accuracy: 0.6192\n",
      "Epoch 10/100\n",
      "4032/4032 [==============================] - 46s 11ms/step - loss: 0.4504 - accuracy: 0.9023 - val_loss: 0.9467 - val_accuracy: 0.6169\n",
      "Epoch 11/100\n",
      "4032/4032 [==============================] - 47s 12ms/step - loss: 0.4225 - accuracy: 0.9070 - val_loss: 0.9565 - val_accuracy: 0.6102\n",
      "Epoch 12/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.4013 - accuracy: 0.9127 - val_loss: 0.9577 - val_accuracy: 0.6192\n",
      "Epoch 13/100\n",
      "4032/4032 [==============================] - 38s 9ms/step - loss: 0.3833 - accuracy: 0.9142 - val_loss: 0.9650 - val_accuracy: 0.6147\n",
      "Epoch 14/100\n",
      "4032/4032 [==============================] - 44s 11ms/step - loss: 0.3634 - accuracy: 0.9174 - val_loss: 0.9857 - val_accuracy: 0.6102\n",
      "Epoch 15/100\n",
      "4032/4032 [==============================] - 44s 11ms/step - loss: 0.3435 - accuracy: 0.9246 - val_loss: 0.9933 - val_accuracy: 0.6080\n",
      "Epoch 16/100\n",
      "4032/4032 [==============================] - 44s 11ms/step - loss: 0.3337 - accuracy: 0.9244 - val_loss: 1.0170 - val_accuracy: 0.5947\n",
      "Epoch 17/100\n",
      "4032/4032 [==============================] - 48s 12ms/step - loss: 0.3201 - accuracy: 0.9273 - val_loss: 1.0173 - val_accuracy: 0.6125\n",
      "Epoch 18/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.3076 - accuracy: 0.9291 - val_loss: 1.0419 - val_accuracy: 0.6214\n",
      "Epoch 19/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.2979 - accuracy: 0.9318 - val_loss: 1.0272 - val_accuracy: 0.6214\n",
      "Epoch 20/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.2957 - accuracy: 0.9320 - val_loss: 1.0441 - val_accuracy: 0.6147\n",
      "Epoch 21/100\n",
      "4032/4032 [==============================] - 44s 11ms/step - loss: 0.2827 - accuracy: 0.9325 - val_loss: 1.0624 - val_accuracy: 0.6036\n",
      "Epoch 22/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.2748 - accuracy: 0.9333 - val_loss: 1.0771 - val_accuracy: 0.6125\n",
      "Epoch 23/100\n",
      "4032/4032 [==============================] - 49s 12ms/step - loss: 0.2686 - accuracy: 0.9382 - val_loss: 1.0702 - val_accuracy: 0.6169\n",
      "Epoch 24/100\n",
      "4032/4032 [==============================] - 45s 11ms/step - loss: 0.2630 - accuracy: 0.9358 - val_loss: 1.0598 - val_accuracy: 0.6258\n",
      "Epoch 25/100\n",
      "4032/4032 [==============================] - 46s 11ms/step - loss: 0.2512 - accuracy: 0.9407 - val_loss: 1.0494 - val_accuracy: 0.6258\n",
      "Epoch 26/100\n",
      "4032/4032 [==============================] - 44s 11ms/step - loss: 0.2477 - accuracy: 0.9405 - val_loss: 1.0873 - val_accuracy: 0.6214\n",
      "Epoch 27/100\n",
      "4032/4032 [==============================] - 40s 10ms/step - loss: 0.2415 - accuracy: 0.9415 - val_loss: 1.0916 - val_accuracy: 0.6214\n",
      "Epoch 28/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.3675 - accuracy: 0.8735 - val_loss: 0.9970 - val_accuracy: 0.5702\n",
      "Epoch 29/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.3216 - accuracy: 0.9008 - val_loss: 1.0237 - val_accuracy: 0.6258\n",
      "Epoch 30/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.2440 - accuracy: 0.9373 - val_loss: 1.0385 - val_accuracy: 0.6258\n",
      "Epoch 31/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.2311 - accuracy: 0.9390 - val_loss: 1.0759 - val_accuracy: 0.6214\n",
      "Epoch 32/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.2244 - accuracy: 0.9407 - val_loss: 1.1054 - val_accuracy: 0.6303\n",
      "Epoch 33/100\n",
      "4032/4032 [==============================] - 34s 9ms/step - loss: 0.2132 - accuracy: 0.9459 - val_loss: 1.1044 - val_accuracy: 0.6325\n",
      "Epoch 34/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.2077 - accuracy: 0.9477 - val_loss: 1.1134 - val_accuracy: 0.6258\n",
      "Epoch 35/100\n",
      "4032/4032 [==============================] - 34s 9ms/step - loss: 0.2032 - accuracy: 0.9459 - val_loss: 1.1361 - val_accuracy: 0.6236\n",
      "Epoch 36/100\n",
      "4032/4032 [==============================] - 35s 9ms/step - loss: 0.1967 - accuracy: 0.9487 - val_loss: 1.1596 - val_accuracy: 0.6303\n",
      "Epoch 37/100\n",
      "4032/4032 [==============================] - 35s 9ms/step - loss: 0.1910 - accuracy: 0.9504 - val_loss: 1.1616 - val_accuracy: 0.6214\n",
      "Epoch 38/100\n",
      "4032/4032 [==============================] - 34s 8ms/step - loss: 0.1874 - accuracy: 0.9524 - val_loss: 1.1589 - val_accuracy: 0.6347\n",
      "Epoch 39/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1843 - accuracy: 0.9511 - val_loss: 1.1841 - val_accuracy: 0.6370\n",
      "Epoch 40/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1806 - accuracy: 0.9529 - val_loss: 1.1826 - val_accuracy: 0.6303\n",
      "Epoch 41/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1797 - accuracy: 0.9494 - val_loss: 1.1858 - val_accuracy: 0.6370\n",
      "Epoch 42/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1750 - accuracy: 0.9524 - val_loss: 1.1966 - val_accuracy: 0.6303\n",
      "Epoch 43/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1755 - accuracy: 0.9511 - val_loss: 1.2099 - val_accuracy: 0.6281\n",
      "Epoch 44/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1709 - accuracy: 0.9516 - val_loss: 1.1916 - val_accuracy: 0.6347\n",
      "Epoch 45/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1662 - accuracy: 0.9559 - val_loss: 1.2080 - val_accuracy: 0.6370\n",
      "Epoch 46/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1654 - accuracy: 0.9546 - val_loss: 1.2036 - val_accuracy: 0.6414\n",
      "Epoch 47/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1624 - accuracy: 0.9561 - val_loss: 1.2130 - val_accuracy: 0.6325\n",
      "Epoch 48/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1610 - accuracy: 0.9556 - val_loss: 1.2254 - val_accuracy: 0.6392\n",
      "Epoch 49/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1546 - accuracy: 0.9576 - val_loss: 1.2284 - val_accuracy: 0.6414\n",
      "Epoch 50/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1523 - accuracy: 0.9581 - val_loss: 1.2352 - val_accuracy: 0.6347\n",
      "Epoch 51/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1510 - accuracy: 0.9571 - val_loss: 1.2721 - val_accuracy: 0.6258\n",
      "Epoch 52/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1524 - accuracy: 0.9586 - val_loss: 1.2843 - val_accuracy: 0.6147\n",
      "Epoch 53/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1468 - accuracy: 0.9593 - val_loss: 1.2998 - val_accuracy: 0.6169\n",
      "Epoch 54/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1440 - accuracy: 0.9593 - val_loss: 1.3175 - val_accuracy: 0.6258\n",
      "Epoch 55/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1384 - accuracy: 0.9608 - val_loss: 1.3272 - val_accuracy: 0.6125\n",
      "Epoch 56/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1409 - accuracy: 0.9611 - val_loss: 1.3209 - val_accuracy: 0.6236\n",
      "Epoch 57/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1386 - accuracy: 0.9621 - val_loss: 1.3381 - val_accuracy: 0.6236\n",
      "Epoch 58/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1361 - accuracy: 0.9628 - val_loss: 1.3409 - val_accuracy: 0.6236\n",
      "Epoch 59/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.1324 - accuracy: 0.9623 - val_loss: 1.3479 - val_accuracy: 0.6192\n",
      "Epoch 60/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.1308 - accuracy: 0.9628 - val_loss: 1.3685 - val_accuracy: 0.6214\n",
      "Epoch 61/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.1328 - accuracy: 0.9621 - val_loss: 1.3888 - val_accuracy: 0.6080\n",
      "Epoch 62/100\n",
      "4032/4032 [==============================] - 36s 9ms/step - loss: 0.1305 - accuracy: 0.9618 - val_loss: 1.4179 - val_accuracy: 0.6058\n",
      "Epoch 63/100\n",
      "4032/4032 [==============================] - 35s 9ms/step - loss: 0.1346 - accuracy: 0.9621 - val_loss: 1.4030 - val_accuracy: 0.6125\n",
      "Epoch 64/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1322 - accuracy: 0.9591 - val_loss: 1.3843 - val_accuracy: 0.6080\n",
      "Epoch 65/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1238 - accuracy: 0.9650 - val_loss: 1.4276 - val_accuracy: 0.6036\n",
      "Epoch 66/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1256 - accuracy: 0.9648 - val_loss: 1.4064 - val_accuracy: 0.6036\n",
      "Epoch 67/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1202 - accuracy: 0.9668 - val_loss: 1.4433 - val_accuracy: 0.6058\n",
      "Epoch 68/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.1184 - accuracy: 0.9645 - val_loss: 1.4565 - val_accuracy: 0.6058\n",
      "Epoch 69/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1184 - accuracy: 0.9650 - val_loss: 1.4581 - val_accuracy: 0.5969\n",
      "Epoch 70/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1228 - accuracy: 0.9643 - val_loss: 1.4556 - val_accuracy: 0.5991\n",
      "Epoch 71/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1188 - accuracy: 0.9650 - val_loss: 1.4602 - val_accuracy: 0.6080\n",
      "Epoch 72/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1154 - accuracy: 0.9665 - val_loss: 1.4706 - val_accuracy: 0.6102\n",
      "Epoch 73/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1142 - accuracy: 0.9663 - val_loss: 1.4742 - val_accuracy: 0.6147\n",
      "Epoch 74/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1125 - accuracy: 0.9660 - val_loss: 1.5062 - val_accuracy: 0.6102\n",
      "Epoch 75/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1116 - accuracy: 0.9683 - val_loss: 1.5247 - val_accuracy: 0.6013\n",
      "Epoch 76/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1125 - accuracy: 0.9660 - val_loss: 1.5214 - val_accuracy: 0.6013\n",
      "Epoch 77/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1102 - accuracy: 0.9658 - val_loss: 1.5045 - val_accuracy: 0.6102\n",
      "Epoch 78/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1137 - accuracy: 0.9658 - val_loss: 1.4931 - val_accuracy: 0.6236\n",
      "Epoch 79/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1148 - accuracy: 0.9650 - val_loss: 1.4904 - val_accuracy: 0.5991\n",
      "Epoch 80/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1110 - accuracy: 0.9683 - val_loss: 1.4807 - val_accuracy: 0.6147\n",
      "Epoch 81/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1072 - accuracy: 0.9695 - val_loss: 1.5039 - val_accuracy: 0.6192\n",
      "Epoch 82/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1102 - accuracy: 0.9668 - val_loss: 1.5179 - val_accuracy: 0.6147\n",
      "Epoch 83/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1107 - accuracy: 0.9653 - val_loss: 1.5560 - val_accuracy: 0.5947\n",
      "Epoch 84/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1042 - accuracy: 0.9690 - val_loss: 1.5676 - val_accuracy: 0.6058\n",
      "Epoch 85/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1047 - accuracy: 0.9665 - val_loss: 1.5768 - val_accuracy: 0.6080\n",
      "Epoch 86/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1060 - accuracy: 0.9685 - val_loss: 1.5433 - val_accuracy: 0.6214\n",
      "Epoch 87/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1092 - accuracy: 0.9660 - val_loss: 1.5338 - val_accuracy: 0.6080\n",
      "Epoch 88/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1029 - accuracy: 0.9683 - val_loss: 1.5240 - val_accuracy: 0.6102\n",
      "Epoch 89/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1049 - accuracy: 0.9663 - val_loss: 1.5351 - val_accuracy: 0.6058\n",
      "Epoch 90/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1010 - accuracy: 0.9705 - val_loss: 1.5514 - val_accuracy: 0.6147\n",
      "Epoch 91/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1012 - accuracy: 0.9675 - val_loss: 1.5562 - val_accuracy: 0.6058\n",
      "Epoch 92/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1001 - accuracy: 0.9692 - val_loss: 1.5719 - val_accuracy: 0.6125\n",
      "Epoch 93/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1034 - accuracy: 0.9678 - val_loss: 1.5905 - val_accuracy: 0.6080\n",
      "Epoch 94/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1051 - accuracy: 0.9663 - val_loss: 1.5764 - val_accuracy: 0.6102\n",
      "Epoch 95/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.1007 - accuracy: 0.9695 - val_loss: 1.5780 - val_accuracy: 0.6102\n",
      "Epoch 96/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.0997 - accuracy: 0.9705 - val_loss: 1.5812 - val_accuracy: 0.6169\n",
      "Epoch 97/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.0989 - accuracy: 0.9700 - val_loss: 1.5955 - val_accuracy: 0.6125\n",
      "Epoch 98/100\n",
      "4032/4032 [==============================] - 33s 8ms/step - loss: 0.0975 - accuracy: 0.9705 - val_loss: 1.6201 - val_accuracy: 0.6058\n",
      "Epoch 99/100\n",
      "4032/4032 [==============================] - 32s 8ms/step - loss: 0.0966 - accuracy: 0.9702 - val_loss: 1.6014 - val_accuracy: 0.5991\n",
      "Epoch 100/100\n",
      "4032/4032 [==============================] - 49s 12ms/step - loss: 0.0939 - accuracy: 0.9700 - val_loss: 1.6250 - val_accuracy: 0.6036\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498/498 [==============================] - 3s 6ms/step\n",
      "Test set\n",
      "  Loss: 1.744\n",
      "  Accuracy: 58.835 %\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f} %'.format(accr[0],accr[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "matrix = metrics.confusion_matrix(Y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[123  42  36]\n",
      " [ 19  68  32]\n",
      " [ 34  42 102]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       201\n",
      "           1       0.45      0.57      0.50       119\n",
      "           2       0.60      0.57      0.59       178\n",
      "\n",
      "    accuracy                           0.59       498\n",
      "   macro avg       0.58      0.59      0.58       498\n",
      "weighted avg       0.60      0.59      0.59       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(Y_test.argmax(axis=1), y_pred.argmax(axis=1)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(Y_test.argmax(axis=1), y_pred.argmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[160  83  33]\n",
      " [ 33 122  38]\n",
      " [ 30  93 155]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.58      0.64       276\n",
      "           1       0.41      0.63      0.50       193\n",
      "           2       0.69      0.56      0.62       278\n",
      "\n",
      "    accuracy                           0.59       747\n",
      "   macro avg       0.60      0.59      0.58       747\n",
      "weighted avg       0.63      0.59      0.59       747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "######XGBoost Implementation####################\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('tfidf', TfidfTransformer()),('classifier', XGBClassifier())])\n",
    "\n",
    "params = {'tfidf__use_idf': (True, False),'bow__analyzer': (lemmas, tokens),'tfidf__norm': ('l1', 'l2'),'classifier__min_child_weight': [5, 10], 'classifier__gamma': [2, 5], 'classifier__subsample': [0.6], 'classifier__max_depth': [5,10]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "xgb_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "import numpy as np\n",
    "# temsg_testdiction_list = np.array(xgb_detector.predict(msg_test))\n",
    "print (confusion_matrix(label_test, xgb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, xgb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209  27  34]\n",
      " [ 56  46  43]\n",
      " [ 31  19 188]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       270\n",
      "           1       0.50      0.32      0.39       145\n",
      "           2       0.71      0.79      0.75       238\n",
      "\n",
      "    accuracy                           0.68       653\n",
      "   macro avg       0.64      0.63      0.62       653\n",
      "weighted avg       0.66      0.68      0.66       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################Uni-Bi#######################\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "######XGBoost Implementation####################\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,2))),('tfidf', TfidfTransformer()),('classifier', XGBClassifier())])\n",
    "\n",
    "params = {'tfidf__use_idf': (True, False),'bow__analyzer': (lemmas, tokens),'tfidf__norm': ('l1', 'l2'),'classifier__min_child_weight': [5, 10], 'classifier__gamma': [2, 5], 'classifier__subsample': [0.6], 'classifier__max_depth': [5,10]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "xgb_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "import numpy as np\n",
    "# temsg_testdiction_list = np.array(xgb_detector.predict(msg_test))\n",
    "print (confusion_matrix(label_test, xgb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, xgb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[209  27  34]\n",
      " [ 56  46  43]\n",
      " [ 31  19 188]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       270\n",
      "           1       0.50      0.32      0.39       145\n",
      "           2       0.71      0.79      0.75       238\n",
      "\n",
      "    accuracy                           0.68       653\n",
      "   macro avg       0.64      0.63      0.62       653\n",
      "weighted avg       0.66      0.68      0.66       653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost\n",
    "######XGBoost Implementation####################\n",
    "#############Uni######\n",
    "# create pipeline\n",
    "pipeline = Pipeline([('bow', CountVectorizer(analyzer=lemmas)),('tfidf', TfidfTransformer()),('classifier', XGBClassifier())])\n",
    "\n",
    "params = {'tfidf__use_idf': (True, False),'bow__analyzer': (lemmas, tokens),'tfidf__norm': ('l1', 'l2'),'classifier__min_child_weight': [5, 10], 'classifier__gamma': [2, 5], 'classifier__subsample': [0.6], 'classifier__max_depth': [5,10]}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "# train\n",
    "xgb_detector = grid.fit(msg_train, label_train)\n",
    "\n",
    "import numpy as np\n",
    "# temsg_testdiction_list = np.array(xgb_detector.predict(msg_test))\n",
    "print (confusion_matrix(label_test, xgb_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, xgb_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[309  27  21]\n",
      " [ 75  77  38]\n",
      " [ 40  29 254]]\n",
      "\n",
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       357\n",
      "           1       0.58      0.41      0.48       190\n",
      "           2       0.81      0.79      0.80       323\n",
      "\n",
      "    accuracy                           0.74       870\n",
      "   macro avg       0.71      0.69      0.69       870\n",
      "weighted avg       0.73      0.74      0.73       870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(ngram_range = (1,3))\n",
    "data_text = vectorizer.fit_transform(data['Text'])\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "msg_train, msg_test, label_train, label_test = train_test_split(data_text, data['Sentiment'], test_size=0.2, random_state=42)\n",
    "###SVM##########################\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# pipe1 = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('classifier', MultinomialNB())])\n",
    "# pipe2 = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('classifier', SVC())])\n",
    "# pipe3 = Pipeline([('bow', CountVectorizer(analyzer=lemmas, ngram_range = (1,3))),('classifier', SGDClassifier(max_iter=1000))])\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "svc = SVC(probability=True)\n",
    "sgd = SGDClassifier(max_iter=1000)\n",
    "lr = LogisticRegression(multi_class='multinomial', solver='newton-cg')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier()\n",
    "voting_clf = VotingClassifier(estimators=[('SVC', svc),\n",
    "                                          ('MNB', mnb),\n",
    "                                          ('LR', lr),\n",
    "                                          ('SGD', sgd)],\n",
    "#                                           ('GBM', gbm)],\n",
    "                                          voting='soft')\n",
    "\n",
    "params = {'SVC__C': [1, 10, 100], 'SVC__gamma': [0.001], 'SVC__kernel': ['rbf', 'linear'],\n",
    "          'MNB__alpha': [1, 1e-1, 1e-2],\n",
    "          'LR__penalty' : ['l2'],'LR__C' : np.logspace(-4, 4, 4),\n",
    "          'SGD__loss': [\"log\", \"modified_huber\"],\"SGD__alpha\" : [0.001, 0.01],\n",
    "          'SGD__penalty' : [\"l2\", \"l1\"]}\n",
    "#           'GBM__loss':[\"deviance\"], 'GBM__max_features': ['auto', 'sqrt', 'log2'], 'GBM__max_depth':[3,5,8], 'GBM__max_features':[\"log2\",\"sqrt\"]}                                          \n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "skf.get_n_splits(msg_train, label_train)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    voting_clf,\n",
    "    params, # parameters to tune via cross validation\n",
    "    refit=True, # fit using all data, on the best detected classifier\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    cv=skf,\n",
    ")\n",
    "\n",
    "ensembling_detector = grid.fit(msg_train, label_train)\n",
    "print (confusion_matrix(label_test, ensembling_detector.predict(msg_test)))\n",
    "print (\"\")\n",
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(label_test, ensembling_detector.predict(msg_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\konark\\\\Downloads\\\\finalized_model_v4.sav']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import joblib\n",
    "filename = r'C:\\Users\\konark\\Downloads\\finalized_model_v4.sav'\n",
    "joblib.dump(ensembling_detector, filename)                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\punjabi_data_v2.csv\", encoding='latin-1', engine='python' )\n",
    "data['Text'] = data['Text'].str.lower()\n",
    "\n",
    "vocabulary = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\generalised_spellings.csv\")\n",
    "vocabulary['Words'] = vocabulary['Words'].str.lower()\n",
    "vocabulary['Generalised Spelling'] = vocabulary['Generalised Spelling'].str.lower()\n",
    "voc_to_be_used = dict(zip(vocabulary['Words'], vocabulary['Generalised Spelling']))\n",
    "\n",
    "replacement_dict = {r'(\\b){}(\\b)'.format(k):r'\\1{}\\2'.format(v) for k,v in voc_to_be_used.items()}\n",
    "data['Text'] = data['Text'].replace(replacement_dict, regex=True)\n",
    "\n",
    "stopwords = [\"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\"]\n",
    "# stopwords = [\"lokk\",'abp\",\"video\", \"aafull\", \"me\", \"rhe\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\", \"bs\", \"chal\", \"jagdeep\", \"captian\", \"anchor\", \"ranjeet\", \"amrinder\", \"ikk\", \"ina\", \"dilli\", \"mai\", \"te\", \"fr\",\"india\", \"singa\", \"tn\", \"dharti\", \"gurdas\", \"singer\", \"sound\", \"live\", \"respiratory\", \"punjab\", \"punjabian\", \"jd\", \"chd\", \"geet\", \"ta\", \"bt\", \"koe\", \"nusrat\", \"fateh\", \"sudhu\", \"sidhu\", \"sukhbir\", \"interview\", \"tumhe\", \"agr\", \"eh\", \"uncle\", \"but\", \"covid\", \"dong\", \"jidaan\", \"matlab\", \"tere\", \"abc\", \"ik\", \"for\",\"news\", \"sanja\", \"tuc\", \"tum\", \"detail\", \"account\", \"accounts\", \"interview\", \"or\", \"diya\", \"add\", \"addmission\", \"address\", \"ade\", \"admin\", \"advocate\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "stopwords = [\"lokk\",\"abp\",\"video\", \"aafull\", \"me\", \"rhe\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", \"10\" ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\", \"bs\", \"chal\", \"jagdeep\", \"captian\", \"anchor\", \"ranjeet\", \"amrinder\", \"ikk\", \"ina\", \"dilli\", \"mai\", \"te\", \"fr\",\"india\", \"singa\", \"tn\", \"dharti\", \"gurdas\", \"singer\", \"sound\", \"live\", \"respiratory\", \"punjab\", \"punjabian\", \"jd\", \"chd\", \"geet\", \"ta\", \"bt\", \"koe\", \"nusrat\", \"fateh\", \"sudhu\", \"sidhu\", \"sukhbir\", \"interview\", \"tumhe\", \"agr\", \"eh\", \"uncle\", \"but\", \"covid\", \"dong\", \"jidaan\", \"matlab\", \"tere\", \"abc\", \"ik\", \"for\",\"news\", \"sanja\", \"tuc\", \"tum\", \"detail\", \"account\", \"accounts\", \"interview\", \"or\", \"diya\", \"add\", \"addmission\", \"address\", \"ade\", \"admin\", \"advocate\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "stopwords = [\"kasoor\", \"ssp\", \"prateek\",\"tu\", \"wabba\", \"pyn\", \"ah\",\"mnu\",\"mai\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "import itertools\n",
    "for i in range(len(data)):\n",
    "    data['Text'][i] = ''.join(''.join(s)[:2] for _, s in itertools.groupby(data['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "########LSTM + WORD2VEC+TF-IDF##################\n",
    "\n",
    "def cleaning_text(original_series):\n",
    "    original_series = original_series.str.replace('(ap)', '')\n",
    "    converting_nt = original_series.str.replace(r'n\\'t',' not')\n",
    "    \n",
    "    removing_trailing_spaces_lowering = converting_nt.str.strip().str.lower()\n",
    "    \n",
    "    removing_special_characters = removing_trailing_spaces_lowering.str.replace(r'[!.:,#-$\\\\\\'0-9]','')\n",
    "    removing_bracket_starting = removing_special_characters.str.replace(r'\\(','')\n",
    "    removing_bracket_ending = removing_bracket_starting.str.replace(r'\\)','')\n",
    "    splitting_into_words = removing_bracket_ending.str.split()\n",
    "    words_greater_than_zero = splitting_into_words[splitting_into_words.map(lambda d: len(d)) > 0]\n",
    "    return (words_greater_than_zero)\n",
    "\n",
    "clean_sentences = cleaning_text(data['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data.Sentiment, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `LabeledSentence` (Class will be removed in 4.0.0, use TaggedDocument instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "\n",
    "def labelizeStories(stories, label_type):\n",
    "    labelized = []\n",
    "    for i,v in enumerate(stories):\n",
    "        label = '%s_%s'%(label_type,i)\n",
    "        labelized.append(LabeledSentence(v, [label]))\n",
    "    return labelized\n",
    "\n",
    "X_train = labelizeStories(X_train, 'TRAIN')\n",
    "X_test = labelizeStories(X_test, 'TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabeledSentence(words='nhi', tags=['TRAIN_0'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model_w2v = Word2Vec(list(clean_sentences), min_count=2,sg=1,window=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=2705, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "print (model_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.4.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.4.0.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bp\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "output_notebook()\n",
    "plot_tfidf = bp.figure(plot_width=700, plot_height=600, title=\"A map of 4210 word vectors\",\n",
    "    tools=\"pan,wheel_zoom,box_zoom,reset,hover,previewsave\",\n",
    "    x_axis_type=None, y_axis_type=None, min_border=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "word_vectors = [model_w2v[w] for w in model_w2v.wv.vocab.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 2705 samples in 0.505s...\n",
      "[t-SNE] Computed neighbors for 2705 samples in 2.935s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 2705\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 2705\n",
      "[t-SNE] Computed conditional probabilities for sample 2705 / 2705\n",
      "[t-SNE] Mean sigma: 0.012451\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 57.484528\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.791110\n"
     ]
    }
   ],
   "source": [
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0)\n",
    "tsne_w2v = tsne_model.fit_transform(word_vectors)\n",
    "\n",
    "# putting everything in a dataframe\n",
    "tsne_df = pd.DataFrame(tsne_w2v, columns=['x', 'y'])\n",
    "tsne_df['words'] = model_w2v.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"11619e91-5204-45f1-9a17-8bb50220a354\" data-root-id=\"1002\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"38490ab4-6fb2-4728-9576-be8866fda65f\":{\"roots\":{\"references\":[{\"attributes\":{\"min_border\":1,\"plot_width\":700,\"renderers\":[{\"id\":\"1030\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"1003\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1019\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"1005\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1002\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1029\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"SaveTool\"},{\"attributes\":{\"source\":{\"id\":\"1026\",\"type\":\"ColumnDataSource\"}},\"id\":\"1031\",\"type\":\"CDSView\"},{\"attributes\":{\"data_source\":{\"id\":\"1026\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1028\",\"type\":\"Scatter\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1029\",\"type\":\"Scatter\"},\"selection_glyph\":null,\"view\":{\"id\":\"1031\",\"type\":\"CDSView\"}},\"id\":\"1030\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1016\",\"type\":\"ResetTool\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"PanTool\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1013\",\"type\":\"PanTool\"},{\"id\":\"1014\",\"type\":\"WheelZoomTool\"},{\"id\":\"1015\",\"type\":\"BoxZoomTool\"},{\"id\":\"1016\",\"type\":\"ResetTool\"},{\"id\":\"1017\",\"type\":\"HoverTool\"},{\"id\":\"1018\",\"type\":\"SaveTool\"}]},\"id\":\"1019\",\"type\":\"Toolbar\"},{\"attributes\":{\"overlay\":{\"id\":\"1033\",\"type\":\"BoxAnnotation\"}},\"id\":\"1015\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1028\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1035\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"callback\":null},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{\"text\":\"A map of 4210 word vectors\"},\"id\":\"1003\",\"type\":\"Title\"},{\"attributes\":{},\"id\":\"1034\",\"type\":\"Selection\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"word\",\"@words\"]]},\"id\":\"1017\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null,\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704],\"words\":[\"coach\",\"nhi\",\"big\",\"jeetenge\",\"kewal\",\"bhag\",\"team\",\"jeetna\",\"dhanyavad\",\"run\",\"media\",\"baat\",\"villain\",\"isliye\",\"kamine\",\"desh\",\"innings\",\"bahut\",\"nice\",\"lot\",\"respect\",\"heart\",\"like\",\"mai\",\"jaroorat\",\"wrong\",\"time\",\"shot\",\"lagan\",\"zarurat\",\"jyada\",\"over\",\"confidence\",\"bhok\",\"bahar\",\"rakhna\",\"bus\",\"haar\",\"sari\",\"english\",\"karna\",\"bade\",\"mistake\",\"lekin\",\"chatukar\",\"kahi\",\"teen\",\"faltu\",\"kharab\",\"management\",\"sala\",\"puri\",\"world\",\"kam\",\"khilaya\",\"semi\",\"final\",\"build\",\"chal\",\"middle\",\"order\",\"last\",\"pura\",\"not\",\"experience\",\"itna\",\"special\",\"treatment\",\"after\",\"flop\",\"clearly\",\"fix\",\"low\",\"score\",\"overconfidence\",\"ban\",\"pita\",\"sabse\",\"khiladi\",\"hai\",\"jitne\",\"usme\",\"ball\",\"jada\",\"khel\",\"fit\",\"bad\",\"umpire\",\"mat\",\"bhool\",\"first\",\"vajse\",\"aki\",\"trip\",\"wah\",\"kutta\",\"aukaat\",\"jitna\",\"acha\",\"kya\",\"love\",\"jinhe\",\"jeet\",\"salute\",\"great\",\"aisa\",\"hua\",\"change\",\"insaaf\",\"such\",\"hoga\",\"superb\",\"number\",\"doubt\",\"politics\",\"khelna\",\"jagah\",\"only\",\"reason\",\"sher\",\"kha\",\"satak\",\"rota\",\"ek\",\"jhakas\",\"sakti\",\"well\",\"played\",\"guroor\",\"wajah\",\"bheek\",\"mango\",\"bechte\",\"ha\",\"moral\",\"sath\",\"bura\",\"khud\",\"karma\",\"kitna\",\"mature\",\"marta\",\"tuk\",\"banaya\",\"paji\",\"bilkul\",\"sahi\",\"naak\",\"logo\",\"ne\",\"out\",\"bana\",\"maja\",\"fantastic\",\"chahiye\",\"galat\",\"natija\",\"bewakoof\",\"dukh\",\"dena\",\"kichar\",\"gendbaaj\",\"yaar\",\"insaan\",\"bol\",\"jawab\",\"sai\",\"legend\",\"paida\",\"hoye\",\"dosh\",\"pehle\",\"upar\",\"samajh\",\"england\",\"asian\",\"smart\",\"kaise\",\"kar\",\"diya\",\"andar\",\"rakhte\",\"sharm\",\"should\",\"position\",\"control\",\"end\",\"please\",\"khilao\",\"mauka\",\"zyada\",\"nei\",\"kiya\",\"new\",\"soch\",\"ghamand\",\"news\",\"baki\",\"rona\",\"band\",\"moron\",\"tarif\",\"ta\",\"international\",\"focus\",\"pata\",\"week\",\"pressure\",\"late\",\"waale\",\"kabhi\",\"karta\",\"chutiya\",\"sharma\",\"banana\",\"aur\",\"samne\",\"miss\",\"phle\",\"agla\",\"karne\",\"bhej\",\"loss\",\"next\",\"trophy\",\"cheese\",\"finish\",\"ability\",\"banda\",\"paas\",\"situation\",\"tou\",\"doob\",\"maro\",\"lag\",\"gaand\",\"and\",\"haha\",\"shayad\",\"law\",\"average\",\"kavi\",\"payenge\",\"janata\",\"hamesha\",\"sunna\",\"motivate\",\"kyuki\",\"unhone\",\"akela\",\"bachaye\",\"jab\",\"dil\",\"listen\",\"der\",\"electricity\",\"bless\",\"all\",\"sale\",\"kutte\",\"right\",\"set\",\"aate\",\"jimmedari\",\"tarha\",\"nibha\",\"much\",\"fixing\",\"harne\",\"khayal\",\"jana\",\"slow\",\"batting\",\"behtar\",\"jeeta\",\"gya\",\"jakar\",\"hissa\",\"support\",\"musalmaan\",\"jeeto\",\"as\",\"bra\",\"bina\",\"mujhe\",\"gaali\",\"pre\",\"sach\",\"haram\",\"maturity\",\"salo\",\"select\",\"log\",\"net\",\"likh\",\"ishan\",\"jb\",\"runs\",\"khola\",\"chota\",\"agai\",\"raja\",\"dekh\",\"padta\",\"kal\",\"gira\",\"jaisa\",\"mig\",\"mean\",\"khabar\",\"li\",\"ba\",\"beta\",\"jaroor\",\"hamare\",\"chaiye\",\"kami\",\"honey\",\"manate\",\"rhy\",\"single\",\"allah\",\"tarf\",\"hara\",\"hero\",\"naya\",\"intzaar\",\"cup\",\"nicha\",\"jhuka\",\"india\",\"bach\",\"chote\",\"nikaal\",\"badhai\",\"raho\",\"message\",\"lanat\",\"player\",\"selector\",\"nikalo\",\"fast\",\"pitch\",\"sali\",\"dusre\",\"tour\",\"gir\",\"bihar\",\"biwi\",\"nikalta\",\"poora\",\"narai\",\"remove\",\"bula\",\"century\",\"marega\",\"haramkhor\",\"baja\",\"tino\",\"maa\",\"ummeed\",\"ghatia\",\"kab\",\"anchor\",\"battameez\",\"thora\",\"fake\",\"aslee\",\"thank\",\"gut\",\"baje\",\"rok\",\"sakta\",\"gend\",\"harkat\",\"le\",\"majaak\",\"jata\",\"hoja\",\"result\",\"zero\",\"fail\",\"best\",\"rhegi\",\"badlega\",\"darinda\",\"harami\",\"baith\",\"hila\",\"raheta\",\"agree\",\"gaya\",\"iska\",\"gum\",\"credit\",\"bal\",\"mu\",\"must\",\"arrogance\",\"proud\",\"inhe\",\"land\",\"phoda\",\"cricketer\",\"baarish\",\"jaayega\",\"vedio\",\"hits\",\"karenge\",\"yeah\",\"zaruri\",\"dub\",\"theek\",\"because\",\"drink\",\"habit\",\"wese\",\"rakhne\",\"aata\",\"wide\",\"sachchai\",\"kahna\",\"dar\",\"ganda\",\"haye\",\"hata\",\"is\",\"moka\",\"luck\",\"crore\",\"shame\",\"plan\",\"pass\",\"cricket\",\"bloody\",\"marji\",\"magar\",\"aake\",\"ho\",\"aaya\",\"aasan\",\"karo\",\"pan\",\"very\",\"aaram\",\"karte\",\"hota\",\"rehti\",\"fight\",\"neend\",\"pta\",\"us\",\"marti\",\"rahey\",\"tati\",\"imaandar\",\"chacha\",\"deshbhakt\",\"fan\",\"chi\",\"baavjood\",\"hpy\",\"every\",\"lndia\",\"ahenkar\",\"thoko\",\"possible\",\"murda\",\"maat\",\"that\",\"khich\",\"semifinal\",\"layak\",\"mohammad\",\"liya\",\"badla\",\"strike\",\"jaan\",\"chud\",\"pakki\",\"bahana\",\"chhod\",\"pahele\",\"koshish\",\"kuch\",\"tri\",\"beizzati\",\"taraf\",\"thoda\",\"sambhal\",\"faasi\",\"salman\",\"khaya\",\"tha\",\"choka\",\"chakkar\",\"favourite\",\"kabutar\",\"cool\",\"hind\",\"find\",\"another\",\"ghanta\",\"ukhad\",\"chatega\",\"sare\",\"sada\",\"phat\",\"karu\",\"karwaya\",\"total\",\"kushi\",\"chhupa\",\"aurat\",\"lagata\",\"dirty\",\"gadha\",\"peeda\",\"how\",\"kafir\",\"karwai\",\"re\",\"balatkar\",\"behen\",\"k\",\"lode\",\"tym\",\"action\",\"baccha\",\"short\",\"khatam\",\"sochta\",\"socha\",\"close\",\"buddha\",\"aega\",\"utna\",\"janta\",\"khoon\",\"p\",\"top\",\"humne\",\"behenchod\",\"bada\",\"bikaau\",\"ata\",\"yaro\",\"rkhna\",\"name\",\"asmaan\",\"asa\",\"merit\",\"na\",\"kamjor\",\"level\",\"choose\",\"paise\",\"khush\",\"wale\",\"jalil\",\"nikalna\",\"mehenga\",\"karoge\",\"bhare\",\"maal\",\"kota\",\"kachra\",\"gaddar\",\"bhakt\",\"kacha\",\"sla\",\"anushka\",\"game\",\"angreji\",\"gulam\",\"chuha\",\"line\",\"lenge\",\"phod\",\"bata\",\"gareeb\",\"waqt\",\"sab\",\"ka\",\"fat\",\"haath\",\"per\",\"bewde\",\"pehlo\",\"fursat\",\"deewana\",\"attack\",\"pakistan\",\"return\",\"gift\",\"yad\",\"pichli\",\"pilay\",\"comedy\",\"case\",\"death\",\"daaru\",\"nasha\",\"khali\",\"subscriber\",\"keeda\",\"bomb\",\"uda\",\"it\",\"deal\",\"firmly\",\"design\",\"bamboo\",\"virus\",\"tarik\",\"taaki\",\"se\",\"samaj\",\"aa\",\"rha\",\"fesla\",\"dukan\",\"khol\",\"mar\",\"jio\",\"wasio\",\"kimat\",\"asar\",\"class\",\"padega\",\"government\",\"jant\",\"god\",\"job\",\"bharta\",\"request\",\"pareshan\",\"hinsa\",\"bhai\",\"spread\",\"atankwaad\",\"surat\",\"haramjade\",\"moblinching\",\"khilaaf\",\"natiza\",\"protest\",\"lathi\",\"charge\",\"izazat\",\"tabrez\",\"katilo\",\"marne\",\"channel\",\"wahi\",\"debate\",\"aadmi\",\"mara\",\"shanti\",\"korne\",\"lewda\",\"permission\",\"tabrej\",\"maar\",\"koi\",\"incident\",\"dete\",\"wha\",\"kanun\",\"saanti\",\"duto\",\"fool\",\"terrorist\",\"parties\",\"followers\",\"suaro\",\"aulad\",\"jannat\",\"godhra\",\"kaun\",\"demand\",\"atayachaar\",\"fati\",\"nikalte\",\"kyu\",\"murkh\",\"marte\",\"kisse\",\"barbaad\",\"commissioner\",\"pistol\",\"taklif\",\"hindutva\",\"nazar\",\"bhikari\",\"dogla\",\"mashaallah\",\"super\",\"takbir\",\"hifajat\",\"goli\",\"good\",\"madarchod\",\"tak\",\"repeat\",\"relies\",\"take\",\"fasaad\",\"non\",\"marna\",\"zehmat\",\"julm\",\"awaaz\",\"bhagwan\",\"really\",\"sara\",\"utpad\",\"asal\",\"office\",\"lati\",\"yo\",\"bekasoor\",\"masum\",\"unpe\",\"parmisan\",\"kidn\",\"maan\",\"danga\",\"ready\",\"talwar\",\"talak\",\"vande\",\"matram\",\"inka\",\"dharam\",\"savidhan\",\"sarkar\",\"dho\",\"chamcha\",\"khte\",\"hal\",\"pankh\",\"izzat\",\"sadko\",\"saja\",\"waisi\",\"mast\",\"mobile\",\"linching\",\"ukhaad\",\"trah\",\"ghaseat\",\"marenge\",\"azad\",\"duniya\",\"shaitaan\",\"ram\",\"hindustan\",\"release\",\"aakhir\",\"sbko\",\"aandolan\",\"jaat\",\"sabhi\",\"real\",\"chor\",\"pagal\",\"barabar\",\"court\",\"kanoon\",\"sabi\",\"department\",\"wafadar\",\"najayaj\",\"jhoot\",\"mary\",\"party\",\"sha\",\"nrc\",\"ca\",\"bill\",\"follow\",\"atanki\",\"bujh\",\"hamla\",\"bheed\",\"sanghi\",\"pathraw\",\"sazish\",\"dalaal\",\"kaum\",\"lal\",\"mulk\",\"halat\",\"gaon\",\"shree\",\"mata\",\"bhosdi\",\"ulanghan\",\"duwara\",\"chada\",\"chain\",\"jiska\",\"mare\",\"chehera\",\"yhan\",\"wala\",\"chahta\",\"bhala\",\"bekar\",\"nuksaan\",\"aag\",\"socho\",\"muslim\",\"shoot\",\"majhab\",\"andhe\",\"jaanvar\",\"tension\",\"addmission\",\"manga\",\"agar\",\"kiss\",\"jara\",\"gardar\",\"rist\",\"maun\",\"raili\",\"brahaman\",\"suruwat\",\"radhi\",\"pakad\",\"medical\",\"guess\",\"birthday\",\"natak\",\"gunda\",\"firing\",\"khade\",\"tamasha\",\"kitne\",\"tumhen\",\"phansi\",\"road\",\"other\",\"gen\",\"sachi\",\"dhiyan\",\"billi\",\"dear\",\"sharam\",\"paltu\",\"rosy\",\"nafrat\",\"rahy\",\"nari\",\"baz\",\"sunu\",\"bhasha\",\"shuru\",\"israeli\",\"sabke\",\"adhikar\",\"khane\",\"aaj\",\"zinda\",\"cover\",\"to\",\"gas\",\"target\",\"mulle\",\"macha\",\"murder\",\"de\",\"mandir\",\"tod\",\"fire\",\"tragedy\",\"response\",\"julus\",\"live\",\"suwar\",\"aadhe\",\"test\",\"amith\",\"peet\",\"kafi\",\"mustaid\",\"standard\",\"sikhata\",\"itihaas\",\"ghusa\",\"beer\",\"pavitra\",\"khate\",\"dahrmik\",\"secular\",\"jehaad\",\"farak\",\"sabkuch\",\"gair\",\"sure\",\"aaye\",\"hindu\",\"jhagda\",\"badnaam\",\"baiman\",\"bharosa\",\"vaala\",\"dila\",\"naukri\",\"police\",\"suwwar\",\"launching\",\"pakar\",\"jhoota\",\"chuki\",\"mandiro\",\"murti\",\"cow\",\"kaat\",\"ekjut\",\"kamyab\",\"kamal\",\"sahab\",\"a\",\"dalit\",\"quran\",\"alawa\",\"religion\",\"jahannum\",\"friend\",\"friendship\",\"relation\",\"yani\",\"unshe\",\"rahe\",\"sikh\",\"chaddi\",\"balo\",\"baba\",\"saheb\",\"ambedkar\",\"jinda\",\"criminal\",\"kasam\",\"khoda\",\"udar\",\"long\",\"mind\",\"tu\",\"hovi\",\"lekar\",\"nikle\",\"protect\",\"onko\",\"militri\",\"lakdi\",\"bora\",\"relationship\",\"without\",\"uncle\",\"zariya\",\"zeher\",\"faila\",\"type\",\"help\",\"mujrim\",\"are\",\"sorry\",\"samya\",\"jala\",\"rakh\",\"sewa\",\"report\",\"zindabad\",\"rehna\",\"yakeen\",\"kayde\",\"kulhadi\",\"gayab\",\"lagega\",\"durga\",\"bajarangi\",\"atank\",\"bathare\",\"upper\",\"thanks\",\"moon\",\"matlab\",\"kata\",\"lie\",\"never\",\"journalist\",\"tell\",\"chup\",\"people\",\"rather\",\"population\",\"hazar\",\"samudaye\",\"paresan\",\"midiya\",\"green\",\"status\",\"feel\",\"sad\",\"humanity\",\"says\",\"hate\",\"made\",\"promise\",\"statement\",\"back\",\"home\",\"hindustani\",\"army\",\"awam\",\"gussa\",\"movie\",\"actress\",\"bat\",\"purana\",\"jet\",\"teh\",\"me\",\"same\",\"feels\",\"others\",\"believe\",\"system\",\"mercy\",\"kush\",\"famous\",\"dislike\",\"bhosdiwale\",\"let\",\"speak\",\"takleef\",\"andaaz\",\"bayan\",\"lauda\",\"char\",\"judge\",\"samjhane\",\"called\",\"intellectual\",\"citizen\",\"padna\",\"deshdrohi\",\"amazing\",\"jo\",\"hard\",\"epic\",\"guru\",\"smjhte\",\"acting\",\"karni\",\"obc\",\"jaag\",\"ticket\",\"lulle\",\"story\",\"lulla\",\"interview\",\"thoonk\",\"part\",\"gang\",\"going\",\"faida\",\"modi\",\"kahani\",\"candidate\",\"vote\",\"atal\",\"kareeb\",\"iljaam\",\"abey\",\"sota\",\"mile\",\"jodi\",\"kodi\",\"saath\",\"beth\",\"yaad\",\"jaahil\",\"lagna\",\"life\",\"sasta\",\"tukde\",\"ukhadna\",\"sabh\",\"sarcasm\",\"thought\",\"intelligence\",\"hold\",\"likha\",\"shabd\",\"industry\",\"ghoomo\",\"enjoy\",\"bandar\",\"emergency\",\"juban\",\"intelligent\",\"omg\",\"know\",\"leader\",\"doosri\",\"wohi\",\"tadipar\",\"aashirwaad\",\"many\",\"political\",\"everything\",\"image\",\"but\",\"commitment\",\"destroy\",\"twitter\",\"which\",\"away\",\"by\",\"idiot\",\"saha\",\"aadat\",\"abhi\",\"mahatma\",\"photo\",\"too\",\"door\",\"side\",\"skill\",\"month\",\"bimar\",\"tumhra\",\"traitor\",\"samjh\",\"samjhte\",\"years\",\"nonsense\",\"darshan\",\"chpal\",\"bhi\",\"kumar\",\"smile\",\"padegi\",\"face\",\"driver\",\"khani\",\"hume\",\"pasand\",\"proof\",\"do\",\"sikha\",\"vision\",\"dream\",\"lucky\",\"dua\",\"sah\",\"field\",\"can\",\"understand\",\"anything\",\"ever\",\"politician\",\"gajab\",\"taking\",\"mother\",\"cause\",\"saaf\",\"karwa\",\"advance\",\"pada\",\"rubbish\",\"bich\",\"still\",\"moti\",\"raha\",\"naseeb\",\"kissi\",\"ise\",\"maloom\",\"jeevan\",\"neta\",\"kahe\",\"answer\",\"bawashir\",\"dimaag\",\"tez\",\"dikkat\",\"voice\",\"suno\",\"style\",\"wahiyaad\",\"journalism\",\"both\",\"rahat\",\"rakhana\",\"sur\",\"up\",\"lol\",\"compare\",\"care\",\"for\",\"always\",\"stop\",\"prime\",\"did\",\"held\",\"conference\",\"bhadwa\",\"video\",\"malik\",\"zindagi\",\"vas\",\"jinka\",\"aankh\",\"saram\",\"sambodhit\",\"kokh\",\"forget\",\"kiska\",\"sanskar\",\"padhe\",\"sunte\",\"samay\",\"khareeda\",\"ppu\",\"khareed\",\"think\",\"try\",\"badal\",\"tk\",\"useless\",\"kalank\",\"makkar\",\"bhangi\",\"jawan\",\"jumma\",\"ishwar\",\"hail\",\"school\",\"poision\",\"speech\",\"during\",\"means\",\"haji\",\"paisa\",\"salon\",\"dying\",\"award\",\"dhobi\",\"sarma\",\"samjhe\",\"samjhega\",\"everyone\",\"doing\",\"ake\",\"muh\",\"business\",\"ask\",\"question\",\"front\",\"wonder\",\"virodh\",\"haq\",\"lund\",\"knowledge\",\"development\",\"badia\",\"spit\",\"chakka\",\"khandan\",\"pesab\",\"true\",\"busy\",\"yhin\",\"dakha\",\"decision\",\"words\",\"crazy\",\"would\",\"seen\",\"billion\",\"atleast\",\"war\",\"mahaan\",\"enough\",\"body\",\"baadshah\",\"rahenge\",\"form\",\"saare\",\"tarh\",\"bastard\",\"cheat\",\"aadarsh\",\"buckner\",\"kash\",\"drs\",\"wakt\",\"fact\",\"those\",\"freedom\",\"rank\",\"paani\",\"steve\",\"bucknor\",\"dushman\",\"empire\",\"icc\",\"rhta\",\"sabki\",\"wife\",\"fuck\",\"committed\",\"dudh\",\"jaya\",\"jalan\",\"karan\",\"faisla\",\"expected\",\"khoti\",\"record\",\"danger\",\"there\",\"though\",\"accept\",\"gave\",\"against\",\"better\",\"boycott\",\"fikar\",\"saad\",\"covid\",\"jamaat\",\"uspe\",\"ramayan\",\"liberal\",\"nangi\",\"doordarshan\",\"hat\",\"aise\",\"lo\",\"sunlo\",\"waalo\",\"maha\",\"bharat\",\"baad\",\"krishna\",\"ravishuddin\",\"naali\",\"kid\",\"gawar\",\"nikla\",\"sabko\",\"bhadka\",\"idea\",\"solution\",\"sikhaya\",\"according\",\"negative\",\"update\",\"chashma\",\"laga\",\"uthane\",\"circus\",\"matra\",\"fasa\",\"haalat\",\"kahete\",\"give\",\"madad\",\"sun\",\"nagrik\",\"lockdown\",\"b\",\"mange\",\"drohi\",\"jamatio\",\"quch\",\"doctor\",\"nurses\",\"manta\",\"fas\",\"star\",\"plus\",\"suru\",\"talk\",\"mask\",\"lagi\",\"dhanda\",\"agenda\",\"randi\",\"sarkaar\",\"jaadu\",\"mental\",\"hospital\",\"ilaaj\",\"mulla\",\"virodhi\",\"mana\",\"maang\",\"consider\",\"tujhse\",\"likhenge\",\"bhojan\",\"miya\",\"becha\",\"head\",\"culture\",\"bin\",\"pat\",\"kanha\",\"mard\",\"halala\",\"kuran\",\"mark\",\"sudhrega\",\"khilaf\",\"rahta\",\"beat\",\"hisab\",\"utha\",\"dog\",\"sunne\",\"hanuman\",\"lega\",\"jal\",\"follower\",\"an\",\"brother\",\"thing\",\"din\",\"ji\",\"shri\",\"get\",\"brain\",\"victim\",\"padh\",\"randwa\",\"kitana\",\"enemy\",\"your\",\"saying\",\"ghar\",\"views\",\"bhosh\",\"active\",\"naik\",\"babu\",\"million\",\"himmat\",\"dare\",\"jhel\",\"bakwas\",\"gobar\",\"sabit\",\"section\",\"ekdum\",\"deserve\",\"dost\",\"dard\",\"ugalte\",\"sbke\",\"sbka\",\"abadi\",\"phdai\",\"hijda\",\"kale\",\"dobara\",\"congress\",\"majdoor\",\"bhook\",\"paidal\",\"important\",\"ghada\",\"check\",\"karle\",\"madharchod\",\"sak\",\"carrier\",\"kejriwal\",\"sawal\",\"direct\",\"leftist\",\"naxali\",\"samjhao\",\"pichwade\",\"patrkar\",\"challenge\",\"sachhi\",\"bharna\",\"mc\",\"corona\",\"mohalla\",\"jihaadi\",\"kadam\",\"badha\",\"free\",\"shaktimaan\",\"tumhari\",\"isne\",\"ab\",\"niti\",\"bhav\",\"poor\",\"yahan\",\"food\",\"khun\",\"khila\",\"khilare\",\"rupe\",\"tax\",\"thi\",\"program\",\"aatma\",\"present\",\"future\",\"nobody\",\"crying\",\"break\",\"most\",\"watch\",\"rahana\",\"come\",\"absolutely\",\"owaisi\",\"sahb\",\"anpadh\",\"madarsa\",\"che\",\"madam\",\"ser\",\"salam\",\"bharti\",\"prati\",\"houses\",\"akbaruddin\",\"uddin\",\"national\",\"sawaal\",\"tumlog\",\"loda\",\"minute\",\"mn\",\"song\",\"mehanat\",\"rang\",\"turkmenistan\",\"beautiful\",\"sundar\",\"gaana\",\"naman\",\"wow\",\"jhalak\",\"beti\",\"joy\",\"mera\",\"hot\",\"student\",\"dhol\",\"ko\",\"awesome\",\"poore\",\"shat\",\"asha\",\"unme\",\"sudha\",\"bakchodi\",\"viswaas\",\"banna\",\"raj\",\"lagta\",\"jhanda\",\"vikas\",\"kasar\",\"lane\",\"garv\",\"vishwas\",\"jor\",\"jazbaa\",\"mahan\",\"videshi\",\"pranam\",\"hajar\",\"subko\",\"ki\",\"lage\",\"samman\",\"jaldi\",\"paar\",\"bigad\",\"jaau\",\"chand\",\"madat\",\"rakho\",\"te\",\"technology\",\"paiso\",\"dhadkan\",\"jaihind\",\"ucha\",\"jai\",\"maje\",\"namaskar\",\"jabardast\",\"roop\",\"nikalega\",\"saksham\",\"my\",\"pradhan\",\"sena\",\"package\",\"silent\",\"mode\",\"flight\",\"kismat\",\"yatra\",\"introduction\",\"karwane\",\"chavi\",\"wish\",\"lakshmi\",\"ajad\",\"bose\",\"paega\",\"pm\",\"uthe\",\"kare\",\"sir\",\"pyar\",\"welcome\",\"navaj\",\"don\",\"pakdo\",\"golden\",\"sna\",\"doopahar\",\"pure\",\"sbhi\",\"fayda\",\"saabit\",\"mission\",\"earth\",\"shath\",\"marg\",\"you\",\"jan\",\"hasta\",\"subh\",\"pyaar\",\"valu\",\"fakre\",\"sarkari\",\"college\",\"pdhate\",\"mud\",\"mananiya\",\"yug\",\"koti\",\"antar\",\"pooja\",\"ekta\",\"milenge\",\"pehna\",\"abki\",\"jhootha\",\"wada\",\"jalsa\",\"subhkamnaye\",\"ja\",\"janam\",\"yojna\",\"chun\",\"ghotale\",\"educated\",\"narak\",\"dus\",\"tabtak\",\"work\",\"roj\",\"gaye\",\"suvar\",\"nirnay\",\"pade\",\"dawat\",\"tar\",\"rhte\",\"power\",\"avatar\",\"saari\",\"manti\",\"jahan\",\"zindabaad\",\"hamara\",\"paison\",\"isme\",\"garam\",\"rojgar\",\"pariwar\",\"sakte\",\"shiksha\",\"shar\",\"aaja\",\"jaoge\",\"choot\",\"tera\",\"picha\",\"trust\",\"jameen\",\"irada\",\"rahoge\",\"berojgaari\",\"mantri\",\"siwa\",\"padha\",\"ultimate\",\"due\",\"bag\",\"heartly\",\"varsh\",\"phirte\",\"saf\",\"ghire\",\"pehchaan\",\"wonderful\",\"safai\",\"aka\",\"account\",\"dhan\",\"day\",\"selfie\",\"save\",\"child\",\"kijiye\",\"dhar\",\"kisaan\",\"iron\",\"chut\",\"lovely\",\"pechle\",\"milkar\",\"swachh\",\"yua\",\"rhenge\",\"rajniti\",\"thakur\",\"kriya\",\"kara\",\"khatm\",\"scheme\",\"petrol\",\"sadak\",\"totally\",\"confuse\",\"maine\",\"suni\",\"lagu\",\"muskil\",\"light\",\"hatkar\",\"jis\",\"kadi\",\"ako\",\"sbi\",\"seekh\",\"touch\",\"rehne\",\"istemaal\",\"uthate\",\"sahe\",\"umar\",\"bajrangi\",\"phasa\",\"likhna\",\"vail\",\"hit\",\"daag\",\"milni\",\"likes\",\"rukh\",\"manjil\",\"sathi\",\"udhar\",\"dhund\",\"tabhi\",\"distance\",\"milo\",\"bottle\",\"pine\",\"isko\",\"laye\",\"jamana\",\"tum\",\"nanga\",\"sadi\",\"women\",\"shirf\",\"babbu\",\"khub\",\"dunga\",\"hope\",\"selected\",\"uma\",\"jindabad\",\"cute\",\"sona\",\"be\",\"teri\",\"hall\",\"josh\",\"karib\",\"supper\",\"pati\",\"vichar\",\"banta\",\"neech\",\"aakhiri\",\"khana\",\"daal\",\"chance\",\"pillay\",\"dhabba\",\"saitan\",\"count\",\"wait\",\"hasan\",\"mangi\",\"jholi\",\"miladi\",\"haters\",\"roll\",\"model\",\"inspire\",\"hu\",\"milne\",\"min\",\"padhte\",\"padhta\",\"wanna\",\"toba\",\"nada\",\"met\",\"shaadi\",\"kamane\",\"ramazan\",\"mahina\",\"ibadat\",\"amir\",\"kajar\",\"battery\",\"meet\",\"tayyar\",\"sweet\",\"_\",\"mahi\",\"king\",\"move\",\"kda\",\"ladki\",\"insert\",\"colour\",\"samjho\",\"reply\",\"wan\",\"uh\",\"chat\",\"dhansu\",\"just\",\"joking\",\"ganesh\",\"look\",\"rock\",\"ladkiya\",\"so\",\"handsome\",\"night\",\"feeling\",\"khudko\",\"dabang\",\"mubarak\",\"or\",\"dum\",\"act\",\"kind\",\"kadak\",\"whats\",\"hokar\",\"haafiz\",\"ladka\",\"alag\",\"superman\",\"meri\",\"khabis\",\"actor\",\"lock\",\"swagat\",\"fashion\",\"comment\",\"rocks\",\"milega\",\"namard\",\"ladke\",\"less\",\"sequal\",\"marry\",\"tujh\",\"par\",\"veer\",\"morning\",\"maaki\",\"laude\",\"ganpati\",\"maachod\",\"ok\",\"dhokebaaj\",\"one\",\"behaviour\",\"oye\",\"assalamu\",\"alaikum\",\"khan\",\"hum\",\"haj\",\"inse\",\"amen\",\"saadi\",\"shock\",\"pichey\",\"kagaz\",\"islamic\",\"islam\",\"namaste\",\"ami\",\"word\",\"rfta\",\"mari\",\"khde\",\"alekum\",\"dance\",\"teaser\",\"cinema\",\"yes\",\"film\",\"bhan\",\"tare\",\"maru\",\"mere\",\"superhit\",\"bajrangbali\",\"faad\",\"osm\",\"salman_bhai\",\"contact\",\"clear\",\"paunga\",\"ramzaan\",\"vaijan\",\"khuda\",\"boss\",\"tara\",\"jani\",\"math\",\"dhoom\",\"aunga\",\"tujhme\",\"kutti\",\"jhand\",\"idar\",\"raat\",\"tadpa\",\"old\",\"dhamki\",\"human\",\"safe\",\"emaan\",\"khor\",\"wary\",\"insaallah\",\"i\",\"samjo\",\"aana\",\"dheele\",\"bhat\",\"achanak\",\"gender\",\"vaar\",\"pichhe\",\"n\",\"gunah\",\"shirk\",\"dhamaal\",\"eid\",\"traffic\",\"kamai\",\"sake\",\"tamasa\",\"excited\",\"share\",\"leye\",\"ghatiya\",\"peeche\",\"nare\",\"tumara\",\"phone\",\"ramdan\",\"kurta\",\"ill\",\"randy\",\"namaj\",\"fancy\",\"superstar\",\"besabri\",\"website\",\"download\",\"marzi\",\"click\",\"father\",\"sultan\",\"thok\",\"aslam\",\"zarur\",\"bareme\",\"we\",\"jashan\",\"bollywood\",\"sisters\",\"unlike\",\"hoon\",\"funda\",\"inbox\",\"thikana\",\"mafi\",\"group\",\"jeene\",\"mua\",\"behad\",\"owsome\",\"worry\",\"inshaallah\",\"hur\",\"sarminda\",\"hova\",\"bahu\",\"denge\",\"nak\",\"lagbag\",\"pictures\",\"saan\",\"rekod\",\"ladkiyo\",\"confirm\",\"cross\",\"increase\",\"jaaye\",\"adab\",\"tune\",\"bond\",\"pawan\",\"milana\",\"block\",\"buster\",\"rocking\",\"at\",\"kitee\",\"track\",\"uttar\",\"hangover\",\"fauji\",\"foot\",\"pakistaniyo\",\"sbki\",\"den\",\"sheer\",\"tut\",\"delete\",\"want\",\"qustion\",\"que\",\"puchne\",\"assalamualaikum\",\"shetan\",\"mausam\",\"inshallah\",\"full\",\"open\",\"toh\",\"gale\",\"tab\",\"already\",\"nahi\",\"shak\",\"sunkar\",\"kisine\",\"bala\",\"no\",\"bass\",\"padhne\",\"eyes\",\"city\",\"bachpan\",\"afwah\",\"isbaar\",\"shaan\",\"famliy\",\"huge\",\"janab\",\"rae\",\"dad\",\"mom\",\"pose\",\"in\",\"diwali\",\"wajood\",\"oh\",\"rkhe\",\"dhakka\",\"where\",\"turkey\",\"idhar\",\"post\",\"fraud\",\"bj\",\"mami\",\"mano\",\"hazir\",\"theatre\",\"kaunsa\",\"halla\",\"bath\",\"intajar\",\"ameen\",\"profile\",\"aaiye\",\"hao\",\"biryani\",\"bhopal\",\"kuwara\",\"entry\",\"bam\",\"mirchi\",\"sec\",\"ppl\",\"wallo\",\"social\",\"rhey\",\"main\",\"meeting\",\"chuke\",\"g\",\"internet\",\"bake\",\"samj\",\"serf\",\"hpen\",\"lift\",\"subah\",\"yaho\",\"promotion\",\"sunday\",\"dhoka\",\"more\",\"banoonga\",\"what\",\"baby\",\"mallum\",\"girlfriend\",\"shooting\",\"bodyguard\",\"rehte\",\"khrab\",\"deedar\",\"sa\",\"poori\",\"kidhar\",\"beg\",\"angdai\",\"fair\",\"awo\",\"roja\",\"karwate\",\"murga\",\"pandy\",\"purani\",\"bheja\",\"address\",\"ajay\",\"pair\",\"parta\",\"mess\",\"baj\",\"draw\",\"miluga\",\"sanam\",\"ju\",\"bye\",\"bhabhi\",\"sochne\",\"rkhne\",\"sound\",\"mouth\",\"magi\",\"blood\",\"bz\",\"shuts\",\"ehsaan\",\"\\u00e3\\u00e2\\u00e3\\u00e2\\u00e3\\u00e2\",\"panday\",\"server\",\"evening\",\"crash\",\"aao\",\"amma\",\"suna\",\"kamar\",\"hii\",\"seena\",\"sirf\",\"sis\",\"sushila\",\"eve\",\"daily\",\"off\",\"prem\",\"pakka\",\"iftar\",\"ullu\",\"rahne\",\"khusi\",\"laaya\",\"pdh\",\"mela\",\"phdega\",\"phr\",\"link\",\"\\u00e3\\u00e2\\u00e2\\u00e3\\u00e2\\u00e2\\u00e3\\u00e2\\u00e2\\u00e3\\u00e2\\u00e2\",\"ladai\",\"ahmed\",\"pohch\",\"aaka\",\"khas\",\"kharaab\",\"nibhana\",\"dialogue\",\"waste\",\"pack\",\"bs\",\"shyad\",\"karunga\",\"assalam\",\"walaikum\",\"dhal\",\"accident\",\"doobara\",\"todi\",\"personaly\",\"hour\",\"replay\",\"masjid\",\"khi\",\"bajne\",\"pyr\",\"ye\",\"matter\",\"lagne\",\"rabba\",\"confused\",\"hurt\",\"study\",\"exam\",\"lakh\",\"helpful\",\"person\",\"club\",\"rat\",\"beach\",\"khtam\",\"tiger\",\"disturb\",\"cat\",\"ga\",\"bbhaai\",\"angry\",\"nali\",\"between\",\"mid\",\"down\",\"bati\",\"korogi\",\"maroge\",\"ghus\",\"veerji\",\"raham\",\"bale\",\"biggest\",\"najar\",\"majbur\",\"warna\",\"year\",\"gal\",\"milege\",\"online\",\"kadar\",\"also\",\"gandan\",\"loves\",\"dahi\",\"reha\",\"md\",\"bhaijaan\",\"samje\",\"topic\",\"lagakar\",\"inteha\",\"khushboo\",\"tripathi\",\"date\",\"shi\",\"adhik\",\"bichare\",\"tharki\",\"yaaro\",\"sabb\",\"sunati\",\"guzar\",\"ah\",\"then\",\"water\",\"salman_khan\",\"jaye\",\"ramzan\",\"missing\",\"kuvh\",\"milke\",\"khabi\",\"akal\",\"dabba\",\"daba\",\"sojao\",\"hukum\",\"musibat\",\"liye\",\"jalne\",\"leneka\",\"sukoon\",\"trailor\",\"rahul\",\"giraftaar\",\"r\",\"samjhne\",\"shukriya\",\"realize\",\"boar\",\"yha\",\"mangne\",\"sent\",\"ghoda\",\"market\",\"cast\",\"bulao\",\"stay\",\"celebrate\",\"rkhta\",\"ke\",\"sikhna\",\"maante\",\"phir\",\"rod\",\"arrest\",\"shakti\",\"mani\",\"buddy\",\"khta\",\"related\",\"tel\",\"mand\",\"pray\",\"nawaj\",\"paheli\",\"mail\",\"chil\",\"ruk\",\"amazon\",\"privacy\",\"animal\",\"phela\",\"kin\",\"di\",\"aam\",\"bajrangi_bhaijaan\",\"her\",\"gd\",\"this\",\"t\",\"shirt\",\"moj\",\"bahubali\",\"originol\",\"shopping\",\"send\",\"ghatna\",\"man\",\"leave\",\"panga\",\"jaise\",\"stayle\",\"farmaye\",\"bur\",\"south\",\"tohfa\",\"touching\",\"kayi\",\"pit\",\"pay\",\"lagao\",\"gurantee\",\"almost\",\"dress\",\"fights\",\"daina\",\"majato\",\"caller\",\"meme\",\"guy\",\"leg\",\"guys\",\"sant\",\"dafa\",\"health\",\"hand\",\"gold\",\"upload\",\"young\",\"yatch\",\"raksha\",\"rip\",\"bholenath\",\"bechara\",\"maut\",\"rehem\",\"volume\",\"farma\",\"quarantine\",\"pilot\",\"bharpai\",\"prayers\",\"insaniyat\",\"fly\",\"nagad\",\"tarike\",\"cyclone\",\"area\",\"soche\",\"decrease\",\"peace\",\"injured\",\"kisi\",\"rupees\",\"honga\",\"manane\",\"mukam\",\"pulwama\",\"pakistaniyon\",\"haadsa\",\"rohingya\",\"china\",\"pahuch\",\"pille\",\"communist\",\"pao\",\"valo\",\"self\",\"vahi\",\"note\",\"namste\",\"tamaam\",\"hasil\",\"jaane\",\"repist\",\"darinde\",\"mardo\",\"saza\",\"perfect\",\"sharminda\",\"uff\",\"finally\",\"justice\",\"milgaya\",\"heaven\",\"karke\",\"karane\",\"rooh\",\"kripa\",\"encounter\",\"pyari\",\"sne\",\"pai\",\"shaant\",\"aansu\",\"unhi\",\"surakshit\",\"attitude\",\"may\",\"unlogo\",\"lakho\",\"moat\",\"nark\",\"phashi\",\"acid\",\"niyam\",\"mele\",\"reist\",\"ander\",\"tarpa\",\"mill\",\"raip\",\"porn\",\"mitta\",\"gardan\",\"samaz\",\"kasoor\",\"suraksha\",\"rule\",\"khatma\",\"jailer\",\"dera\",\"gangster\",\"tihar\",\"kumud\",\"anjam\",\"beyhadh\",\"speechless\",\"rating\",\"memer\",\"winner\",\"tech\",\"masala\",\"underwear\",\"brand\",\"technical\",\"feature\",\"memes\",\"pro\",\"yeh\",\"unbox\",\"therepy\",\"bidu\",\"darte\",\"thery\",\"pocket\",\"aar\",\"magic\",\"limit\",\"rkha\",\"shii\",\"chijo\",\"projector\",\"tharkiyo\",\"features\",\"disable\",\"halka\",\"chikh\",\"money\",\"londa\",\"varna\",\"riski\",\"review\",\"manna\",\"khatra\",\"utar\",\"danda\",\"dawa\",\"samajhte\",\"sabak\",\"sipahi\",\"language\",\"defence\",\"niklega\",\"constable\",\"heard\",\"reaction\",\"filmy\",\"alam\",\"shipahi\",\"royal\",\"laal\",\"laat\",\"join\",\"ilaake\",\"military\",\"guns\",\"treat\",\"pila\",\"gathering\",\"patthar\",\"saman\",\"bandook\",\"maka\",\"sidha\",\"jamaati\",\"eelaj\",\"tabligi\",\"jude\",\"murdabad\",\"jail\",\"nsa\",\"ladla\",\"pitai\",\"wash\",\"seal\",\"paid\",\"jaha\",\"gujarish\",\"positive\",\"madrachod\",\"ghandwa\",\"rahie\",\"judaai\",\"force\",\"ispar\",\"fear\",\"tabliki\",\"inko\",\"katwa\",\"sankat\",\"recovery\",\"zamat\",\"saboot\",\"tule\",\"jisme\",\"pelo\",\"nani\",\"facility\",\"seize\",\"fela\",\"whole\",\"jamaatio\",\"laaj\",\"innocent\",\"sidhe\",\"footage\",\"pradesh\",\"shere\",\"babar\",\"jehaadi\",\"ghati\",\"heading\",\"divide\",\"ekhata\",\"turnt\",\"badtar\",\"minority\",\"besharam\",\"spot\",\"issue\",\"vahan\",\"ukhar\",\"injection\",\"jurm\",\"majduro\",\"property\",\"stone\",\"place\",\"bullet\",\"cough\",\"rajya\",\"jagruk\",\"instead\",\"kaidi\",\"cctv\",\"ungli\",\"viral\",\"mujra\",\"rupya\",\"does\",\"difference\",\"diploma\",\"youtuber\",\"flow\",\"tiktok\",\"disk\",\"dis\",\"higher\",\"education\",\"onwards\",\"tere\",\"kitaab\",\"kitaabe\",\"gujjar\",\"akrot\",\"roast\",\"stand\",\"recording\",\"teacher\",\"bhau\",\"fighting\",\"unity\",\"dogs\",\"asshole\",\"sadhvi\",\"batwara\",\"bhasan\",\"sing\"],\"x\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[2705]},\"y\":{\"__ndarray__\":\"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\",\"dtype\":\"float32\",\"shape\":[2705]}},\"selected\":{\"id\":\"1034\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1035\",\"type\":\"UnionRenderers\"}},\"id\":\"1026\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":{\"value\":0.5},\"fill_color\":{\"value\":\"lightgrey\"},\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":{\"value\":1.0},\"line_color\":{\"value\":\"black\"},\"line_dash\":[4,4],\"line_width\":{\"value\":2},\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1033\",\"type\":\"BoxAnnotation\"}],\"root_ids\":[\"1002\"]},\"title\":\"Bokeh Application\",\"version\":\"1.4.0\"}};\n",
       "  var render_items = [{\"docid\":\"38490ab4-6fb2-4728-9576-be8866fda65f\",\"roots\":{\"1002\":\"11619e91-5204-45f1-9a17-8bb50220a354\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1002"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tfidf.scatter(x='x', y='y', source=tsne_df)\n",
    "hover = plot_tfidf.select(dict(type=HoverTool))\n",
    "hover.tooltips={\"word\": \"@words\"}\n",
    "show(plot_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tf-idf matrix ...\n",
      "vocab size : 43\n"
     ]
    }
   ],
   "source": [
    "print ('building tf-idf matrix ...')\n",
    "vectorizer = TfidfVectorizer(analyzer=lambda x: x, min_df=2)\n",
    "matrix = vectorizer.fit_transform([x.words for x in X_train])\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print ('vocab size :', len(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tokens, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "#     count = 0.\n",
    "    count = 1\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model_w2v[word].reshape((1, size)) * tfidf[word]\n",
    "#             count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n",
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "train_vecs_w2v = np.concatenate([buildWordVector(z, 100) for z in map(lambda x: x.words, X_train)])\n",
    "train_vecs_w2v = scale(train_vecs_w2v)\n",
    "\n",
    "test_vecs_w2v = np.concatenate([buildWordVector(z, 100) for z in map(lambda x: x.words, X_test)])\n",
    "test_vecs_w2v = scale(test_vecs_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=100))\n",
    "model.add(Dense(32, activation='sigmoid'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 3s - loss: -7.0999e-01 - accuracy: 0.3103\n",
      "Epoch 2/100\n",
      " - 1s - loss: -1.1583e+00 - accuracy: 0.3103\n",
      "Epoch 3/100\n",
      " - 1s - loss: -1.1748e+00 - accuracy: 0.3103\n",
      "Epoch 4/100\n",
      " - 1s - loss: -1.1812e+00 - accuracy: 0.3103\n",
      "Epoch 5/100\n",
      " - 1s - loss: -1.1876e+00 - accuracy: 0.3103\n",
      "Epoch 6/100\n",
      " - 1s - loss: -1.1905e+00 - accuracy: 0.3103\n",
      "Epoch 7/100\n",
      " - 1s - loss: -1.1931e+00 - accuracy: 0.3103\n",
      "Epoch 8/100\n",
      " - 1s - loss: -1.1989e+00 - accuracy: 0.3103\n",
      "Epoch 9/100\n",
      " - 1s - loss: -1.2024e+00 - accuracy: 0.3103\n",
      "Epoch 10/100\n",
      " - 1s - loss: -1.1974e+00 - accuracy: 0.3103\n",
      "Epoch 11/100\n",
      " - 1s - loss: -1.2089e+00 - accuracy: 0.3103\n",
      "Epoch 12/100\n",
      " - 1s - loss: -1.2015e+00 - accuracy: 0.3103\n",
      "Epoch 13/100\n",
      " - 1s - loss: -1.2061e+00 - accuracy: 0.3103\n",
      "Epoch 14/100\n",
      " - 2s - loss: -1.2117e+00 - accuracy: 0.3103\n",
      "Epoch 15/100\n",
      " - 1s - loss: -1.2117e+00 - accuracy: 0.3103\n",
      "Epoch 16/100\n",
      " - 1s - loss: -1.2177e+00 - accuracy: 0.3103\n",
      "Epoch 17/100\n",
      " - 1s - loss: -1.2146e+00 - accuracy: 0.3103\n",
      "Epoch 18/100\n",
      " - 1s - loss: -1.2230e+00 - accuracy: 0.3103\n",
      "Epoch 19/100\n",
      " - 1s - loss: -1.2324e+00 - accuracy: 0.3103\n",
      "Epoch 20/100\n",
      " - 1s - loss: -1.2246e+00 - accuracy: 0.3103\n",
      "Epoch 21/100\n",
      " - 1s - loss: -1.2231e+00 - accuracy: 0.3103\n",
      "Epoch 22/100\n",
      " - 1s - loss: -1.2181e+00 - accuracy: 0.3103\n",
      "Epoch 23/100\n",
      " - 1s - loss: -1.2532e+00 - accuracy: 0.3103\n",
      "Epoch 24/100\n",
      " - 1s - loss: -1.2479e+00 - accuracy: 0.3103\n",
      "Epoch 25/100\n",
      " - 1s - loss: -1.2307e+00 - accuracy: 0.3103\n",
      "Epoch 26/100\n",
      " - 1s - loss: -1.2507e+00 - accuracy: 0.3103\n",
      "Epoch 27/100\n",
      " - 1s - loss: -1.2322e+00 - accuracy: 0.3103\n",
      "Epoch 28/100\n",
      " - 2s - loss: -1.2529e+00 - accuracy: 0.3103\n",
      "Epoch 29/100\n",
      " - 1s - loss: -1.2661e+00 - accuracy: 0.3103\n",
      "Epoch 30/100\n",
      " - 1s - loss: -1.2660e+00 - accuracy: 0.3103\n",
      "Epoch 31/100\n",
      " - 1s - loss: -1.2980e+00 - accuracy: 0.3103\n",
      "Epoch 32/100\n",
      " - 1s - loss: -1.2570e+00 - accuracy: 0.3103\n",
      "Epoch 33/100\n",
      " - 1s - loss: -1.3256e+00 - accuracy: 0.3103\n",
      "Epoch 34/100\n",
      " - 1s - loss: -1.2299e+00 - accuracy: 0.3103\n",
      "Epoch 35/100\n",
      " - 1s - loss: -1.2363e+00 - accuracy: 0.3103\n",
      "Epoch 36/100\n",
      " - 1s - loss: -1.2862e+00 - accuracy: 0.3101\n",
      "Epoch 37/100\n",
      " - 1s - loss: -1.2099e+00 - accuracy: 0.3103\n",
      "Epoch 38/100\n",
      " - 1s - loss: -1.2203e+00 - accuracy: 0.3103\n",
      "Epoch 39/100\n",
      " - 1s - loss: -1.2898e+00 - accuracy: 0.3103\n",
      "Epoch 40/100\n",
      " - 1s - loss: -1.2272e+00 - accuracy: 0.3103\n",
      "Epoch 41/100\n",
      " - 1s - loss: -1.3417e+00 - accuracy: 0.3103\n",
      "Epoch 42/100\n",
      " - 2s - loss: -1.3639e+00 - accuracy: 0.3103\n",
      "Epoch 43/100\n",
      " - 1s - loss: -1.3489e+00 - accuracy: 0.3103\n",
      "Epoch 44/100\n",
      " - 1s - loss: -1.3613e+00 - accuracy: 0.3103\n",
      "Epoch 45/100\n",
      " - 1s - loss: -1.3980e+00 - accuracy: 0.3103\n",
      "Epoch 46/100\n",
      " - 1s - loss: -1.3190e+00 - accuracy: 0.3103\n",
      "Epoch 47/100\n",
      " - 1s - loss: -1.1797e+00 - accuracy: 0.3103\n",
      "Epoch 48/100\n",
      " - 1s - loss: -1.3127e+00 - accuracy: 0.3103\n",
      "Epoch 49/100\n",
      " - 1s - loss: -1.4023e+00 - accuracy: 0.3103\n",
      "Epoch 50/100\n",
      " - 1s - loss: -1.3138e+00 - accuracy: 0.3103\n",
      "Epoch 51/100\n",
      " - 1s - loss: -1.2896e+00 - accuracy: 0.3103\n",
      "Epoch 52/100\n",
      " - 1s - loss: -1.3283e+00 - accuracy: 0.3103\n",
      "Epoch 53/100\n",
      " - 1s - loss: -1.4233e+00 - accuracy: 0.3103\n",
      "Epoch 54/100\n",
      " - 1s - loss: -1.3888e+00 - accuracy: 0.3103\n",
      "Epoch 55/100\n",
      " - 1s - loss: -1.3928e+00 - accuracy: 0.3103\n",
      "Epoch 56/100\n",
      " - 2s - loss: -1.4054e+00 - accuracy: 0.3103\n",
      "Epoch 57/100\n",
      " - 2s - loss: -1.3568e+00 - accuracy: 0.3103\n",
      "Epoch 58/100\n",
      " - 1s - loss: -1.1981e+00 - accuracy: 0.3103\n",
      "Epoch 59/100\n",
      " - 1s - loss: -1.4145e+00 - accuracy: 0.3103\n",
      "Epoch 60/100\n",
      " - 1s - loss: -1.3707e+00 - accuracy: 0.3106\n",
      "Epoch 61/100\n",
      " - 1s - loss: -1.4466e+00 - accuracy: 0.3108\n",
      "Epoch 62/100\n",
      " - 1s - loss: -1.3289e+00 - accuracy: 0.3121\n",
      "Epoch 63/100\n",
      " - 1s - loss: -1.2861e+00 - accuracy: 0.3103\n",
      "Epoch 64/100\n",
      " - 1s - loss: -1.4421e+00 - accuracy: 0.3148\n",
      "Epoch 65/100\n",
      " - 1s - loss: -1.4235e+00 - accuracy: 0.3111\n",
      "Epoch 66/100\n",
      " - 1s - loss: -1.4132e+00 - accuracy: 0.3108\n",
      "Epoch 67/100\n",
      " - 1s - loss: -1.4460e+00 - accuracy: 0.3123\n",
      "Epoch 68/100\n",
      " - 1s - loss: -1.3867e+00 - accuracy: 0.3118\n",
      "Epoch 69/100\n",
      " - 1s - loss: -1.3405e+00 - accuracy: 0.3103\n",
      "Epoch 70/100\n",
      " - 1s - loss: -1.4180e+00 - accuracy: 0.3126\n",
      "Epoch 71/100\n",
      " - 1s - loss: -1.3830e+00 - accuracy: 0.3103\n",
      "Epoch 72/100\n",
      " - 1s - loss: -1.2598e+00 - accuracy: 0.3103\n",
      "Epoch 73/100\n",
      " - 1s - loss: -1.3954e+00 - accuracy: 0.3108\n",
      "Epoch 74/100\n",
      " - 1s - loss: -1.4208e+00 - accuracy: 0.3106\n",
      "Epoch 75/100\n",
      " - 1s - loss: -1.3610e+00 - accuracy: 0.3106\n",
      "Epoch 76/100\n",
      " - 1s - loss: -1.2157e+00 - accuracy: 0.3126\n",
      "Epoch 77/100\n",
      " - 1s - loss: -1.3971e+00 - accuracy: 0.3113\n",
      "Epoch 78/100\n",
      " - 1s - loss: -1.3726e+00 - accuracy: 0.3103\n",
      "Epoch 79/100\n",
      " - 1s - loss: -1.3272e+00 - accuracy: 0.3126\n",
      "Epoch 80/100\n",
      " - 1s - loss: -1.3971e+00 - accuracy: 0.3103\n",
      "Epoch 81/100\n",
      " - 1s - loss: -1.4241e+00 - accuracy: 0.3103\n",
      "Epoch 82/100\n",
      " - 1s - loss: -1.3930e+00 - accuracy: 0.3103\n",
      "Epoch 83/100\n",
      " - 1s - loss: -1.3517e+00 - accuracy: 0.3103\n",
      "Epoch 84/100\n",
      " - 1s - loss: -1.3839e+00 - accuracy: 0.3103\n",
      "Epoch 85/100\n",
      " - 1s - loss: -9.9132e-01 - accuracy: 0.3103\n",
      "Epoch 86/100\n",
      " - 1s - loss: -1.0099e+00 - accuracy: 0.3118\n",
      "Epoch 87/100\n",
      " - 1s - loss: -1.3364e+00 - accuracy: 0.3103\n",
      "Epoch 88/100\n",
      " - 1s - loss: -1.3200e+00 - accuracy: 0.3103\n",
      "Epoch 89/100\n",
      " - 1s - loss: -1.3870e+00 - accuracy: 0.3121\n",
      "Epoch 90/100\n",
      " - 1s - loss: -1.3445e+00 - accuracy: 0.3108\n",
      "Epoch 91/100\n",
      " - 1s - loss: -1.1632e+00 - accuracy: 0.3146\n",
      "Epoch 92/100\n",
      " - 1s - loss: -1.3072e+00 - accuracy: 0.3113\n",
      "Epoch 93/100\n",
      " - 1s - loss: -1.3522e+00 - accuracy: 0.3138\n",
      "Epoch 94/100\n",
      " - 1s - loss: -1.3963e+00 - accuracy: 0.3103\n",
      "Epoch 95/100\n",
      " - 2s - loss: -1.4378e+00 - accuracy: 0.3108\n",
      "Epoch 96/100\n",
      " - 1s - loss: -1.3663e+00 - accuracy: 0.3103\n",
      "Epoch 97/100\n",
      " - 1s - loss: -1.3795e+00 - accuracy: 0.3108\n",
      "Epoch 98/100\n",
      " - 1s - loss: -1.3571e+00 - accuracy: 0.3108\n",
      "Epoch 99/100\n",
      " - 1s - loss: -1.3823e+00 - accuracy: 0.3103\n",
      "Epoch 100/100\n",
      " - 1s - loss: -1.4440e+00 - accuracy: 0.3106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x24af1f7cb88>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_vecs_w2v, y_train, epochs=100, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_vecs_w2v, y_test, batch_size=128, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 28.21285128593445 %\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy', score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################BI-DIRECTIONAL LSTM##########################################\n",
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, CuDNNLSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Input, Embedding, Dense, Conv2D, MaxPool2D, concatenate\n",
    "from keras.layers import Reshape, Flatten, Concatenate, Dropout, SpatialDropout1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import re\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some Global Variables\n",
    "max_features = 100000 # Maximum Number of words we want to include in our dictionary\n",
    "maxlen = 72 # No of words in question we want to create a sequence with\n",
    "embed_size = 300# Size of word to vec embedding we are using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\punjabi_data_v2.csv\", encoding='latin-1', engine='python' )\n",
    "data['Text'] = data['Text'].str.lower()\n",
    "\n",
    "vocabulary = pd.read_csv(r\"C:\\Users\\konark\\Downloads\\generalised_spellings.csv\")\n",
    "vocabulary['Words'] = vocabulary['Words'].str.lower()\n",
    "vocabulary['Generalised Spelling'] = vocabulary['Generalised Spelling'].str.lower()\n",
    "voc_to_be_used = dict(zip(vocabulary['Words'], vocabulary['Generalised Spelling']))\n",
    "\n",
    "replacement_dict = {r'(\\b){}(\\b)'.format(k):r'\\1{}\\2'.format(v) for k,v in voc_to_be_used.items()}\n",
    "data['Text'] = data['Text'].replace(replacement_dict, regex=True)\n",
    "\n",
    "stopwords = [\"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\"]\n",
    "# stopwords = [\"lokk\",'abp\",\"video\", \"aafull\", \"me\", \"rhe\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\", \"bs\", \"chal\", \"jagdeep\", \"captian\", \"anchor\", \"ranjeet\", \"amrinder\", \"ikk\", \"ina\", \"dilli\", \"mai\", \"te\", \"fr\",\"india\", \"singa\", \"tn\", \"dharti\", \"gurdas\", \"singer\", \"sound\", \"live\", \"respiratory\", \"punjab\", \"punjabian\", \"jd\", \"chd\", \"geet\", \"ta\", \"bt\", \"koe\", \"nusrat\", \"fateh\", \"sudhu\", \"sidhu\", \"sukhbir\", \"interview\", \"tumhe\", \"agr\", \"eh\", \"uncle\", \"but\", \"covid\", \"dong\", \"jidaan\", \"matlab\", \"tere\", \"abc\", \"ik\", \"for\",\"news\", \"sanja\", \"tuc\", \"tum\", \"detail\", \"account\", \"accounts\", \"interview\", \"or\", \"diya\", \"add\", \"addmission\", \"address\", \"ade\", \"admin\", \"advocate\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "stopwords = [\"lokk\",\"abp\",\"video\", \"aafull\", \"me\", \"rhe\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", \"10\" ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\", \"bs\", \"chal\", \"jagdeep\", \"captian\", \"anchor\", \"ranjeet\", \"amrinder\", \"ikk\", \"ina\", \"dilli\", \"mai\", \"te\", \"fr\",\"india\", \"singa\", \"tn\", \"dharti\", \"gurdas\", \"singer\", \"sound\", \"live\", \"respiratory\", \"punjab\", \"punjabian\", \"jd\", \"chd\", \"geet\", \"ta\", \"bt\", \"koe\", \"nusrat\", \"fateh\", \"sudhu\", \"sidhu\", \"sukhbir\", \"interview\", \"tumhe\", \"agr\", \"eh\", \"uncle\", \"but\", \"covid\", \"dong\", \"jidaan\", \"matlab\", \"tere\", \"abc\", \"ik\", \"for\",\"news\", \"sanja\", \"tuc\", \"tum\", \"detail\", \"account\", \"accounts\", \"interview\", \"or\", \"diya\", \"add\", \"addmission\", \"address\", \"ade\", \"admin\", \"advocate\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "stopwords = [\"k\",\"c\",\"kasoor\", \"ssp\", \"prateek\",\"tu\", \"wabba\", \"pyn\", \"ah\",\"mnu\",\"mai\", \"100ch\", \"march\", \"april\", \"21\", \"2018\", \"april\", \"20\", \"1st\", \"19\", \"15\", \"urs\", \"14\", \"11\", \"108\", \"100\", '10' ,\"ch\", \"di\", \"aa\",\"wich\",\"bai\",\"meri\",\"v\",\"isa\",\"jisa\",\"vica\",\"taka\",\"vi\",\"othon\",\"nahim\",\"bhi\",\"valom\",\"iha \",\"iha \",\"jadom\",\"kai\",\"tada\",\"andar\",\"utte\",\"sabuta\",\"kadi\",\"nem\",\"ji\",\"kise\",\"pūra\",\"ne\",\"hove\",\"jekar\",\"de\",\"jehara\",\"baada\",\"sara\",\"cho\",\"kade\",\"sab\",\"tan\",\"ki\",\"na\",\"huna\",\"jinam\",\"nala\",\"cahe\",\"kisa \",\"pichom\",\"edhara\",\"nu\",\"ajihe\",\"hi\",\"ke\",\"hain\",\"bahuta\",\"kaafi\",\"huṇe\",\"lai\",\"ki\",\"magara\",\"da\",\"tarham\",\"phera\",\"vele\",\"othe\",\"kite\",\"ithe\",\"jinhanu\",\"jad\",\"vanga \",\"doraan\",\"varaga\",\"jo\",\"la\",\"pura\",\"naale\",\"ton\",\"hona\",\"paso\",\"jeha\",\"es\",\"jina\",\"kujh\",\"dobara\",\"sadda\",\"ethe\",\"bare\",\"kad\",\"kadde\",\"hoye\",\"rahe\",\"bano\",\"deṇi\",\"pia \",\"hoia\",\"gai\",\"laga\",\"huda\",\"janda\",\"vēkha\",\"suṇa\",\"ai\",\"sakde\",\"jave\",\"janda\",\"karke\",\"bilkul\",\"eho\",\"kaun\",\"pher\",\"tad\",\"kolon\",\"kina\",\"jive\",\"hethan\",\"sare\",\"jithe\",\"koi\",\"ki\",\"je\",\"dian\",\"chala\",\"lai\",\"aakh\",\"baṇa\",\"kara\",\"pain\",\"keh\",\"chuke\",\"keha\", \"karvayei\",\"banaye\",\"kitta\",\"javan\",\"dekh\",\"adi\",\"lia\",\"karana\",\"lagoda\",\"aave\",\"kari\",\"laeya\",\"reh\",\"uha\",\"sam\",\"sabha\",\"hana\",\"tu\",\"si\",\"ho\", \"tennu\",\"tusa\",\"hain\",\"hai\",\"apna\",\"je\",\"aate\",\"jam\",\"kal\",\"vagaira\",\"rakh\",\"laag\",\"gal\",\"pi\",\"a\",\"reha\",\"geya\",\"otha\",\"rahi\",\"usne\",\"tusi\",\"mera\",\"usdi\",\"tera\",\"us\",\"oye\",\"aap\",\"san\",\"mein\",\"tusi\",\"assi\",\"par\",\"te\",\"tam\",\"bhavem\",\"aagali\",\"varg\",\"ama\",\"la\",\"hala\",\"ek\", \"tuhada\",\"kita\",\"karde\",\"krde\",\"teri\",\"apne\",\"aj\",\"singh\",\"sikh\",\"ohne\",\"dekh\",\"tuhadi\",\"fir\",\"time\",\"bawa\",\"sidhu\",\"vich\",\"sach\",\"naal\",\"hor\",\"ki\",\"mainu\",\"aaa\",\"wale\",\"hor\",\"krn\",\"kudi\",\"kuj\", \"12\", \"2020\", \"30\", \"300\", \"pwa\", \"do\", \"log\", \"3may\", \"35\", \"40\", \"din\", \"400\", \"50\", \"km\", \"door\", \"5911\", \"50m\", \"3bisby\", \"500\", \"6month\", \"700\", \"900\", \"__\", \"honi\", \"aab\", \"which\", \"ohi\", \"hr\", \"to\", \"aae\"]\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(stopwords))\n",
    "data['Text'] = data['Text'].str.replace(pat, '')\n",
    "data['Text'] = data['Text'].str.replace(r'\\s+', ' ')\n",
    "import itertools\n",
    "for i in range(len(data)):\n",
    "    data['Text'][i] = ''.join(''.join(s)[:2] for _, s in itertools.groupby(data['Text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (4979, 3)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=20000, split=' ')\n",
    "\n",
    "tokenizer.fit_on_texts(data['Text'])\n",
    "X = tokenizer.texts_to_sequences(data['Text'])\n",
    "X = pad_sequences(X)\n",
    "# Y = data['Sentiment']\n",
    "\n",
    "Y = pd.get_dummies(data['Sentiment']).values\n",
    "print('Shape of label tensor:', Y.shape)\n",
    "\n",
    "# We can then create our train and test sets:\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.15, random_state = 42)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data['Text'], data.Sentiment, test_size=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4232, 59) (4232, 3)\n",
      "(747, 59) (747, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words\n",
    "# (among top max_features most common words)\n",
    "maxlen = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (4232, 100)\n",
      "x_test shape: (747, 100)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "y_train = np.array(Y_train)\n",
    "y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(11000, embed_dim = 128, input_length = X.shape[1], dropout=0.2))\n",
    "# model.add( Bidirectional( LSTM(lstm_out = 196, dropout_U = 0.2, dropout_W = 0.2)))\n",
    "# model.add( Dense(3, activation = 'softmax'))\n",
    "\n",
    "# model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  try using different optimizers and different optimizer configs\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "WARNING:tensorflow:From C:\\Users\\konark\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.6088 - accuracy: 0.6836\n",
      "Epoch 2/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.4574 - accuracy: 0.7831\n",
      "Epoch 3/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.3344 - accuracy: 0.8583\n",
      "Epoch 4/100\n",
      "4232/4232 [==============================] - 37s 9ms/step - loss: 0.2302 - accuracy: 0.9147\n",
      "Epoch 5/100\n",
      "4232/4232 [==============================] - 41s 10ms/step - loss: 0.1743 - accuracy: 0.9356\n",
      "Epoch 6/100\n",
      "4232/4232 [==============================] - 38s 9ms/step - loss: 0.1435 - accuracy: 0.9460\n",
      "Epoch 7/100\n",
      "4232/4232 [==============================] - 35s 8ms/step - loss: 0.1217 - accuracy: 0.9557\n",
      "Epoch 8/100\n",
      "4232/4232 [==============================] - 36s 9ms/step - loss: 0.1081 - accuracy: 0.9607\n",
      "Epoch 9/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.1031 - accuracy: 0.9612\n",
      "Epoch 10/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0943 - accuracy: 0.9635\n",
      "Epoch 11/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0888 - accuracy: 0.9652\n",
      "Epoch 12/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0857 - accuracy: 0.9669\n",
      "Epoch 13/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0779 - accuracy: 0.9681\n",
      "Epoch 14/100\n",
      "4232/4232 [==============================] - 35s 8ms/step - loss: 0.0793 - accuracy: 0.9691\n",
      "Epoch 15/100\n",
      "4232/4232 [==============================] - 35s 8ms/step - loss: 0.0758 - accuracy: 0.9692\n",
      "Epoch 16/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0708 - accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0746 - accuracy: 0.9670\n",
      "Epoch 18/100\n",
      "4232/4232 [==============================] - 25s 6ms/step - loss: 0.0678 - accuracy: 0.9716 0s - loss: 0.0673 - accura\n",
      "Epoch 19/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0701 - accuracy: 0.9705\n",
      "Epoch 20/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0679 - accuracy: 0.9712\n",
      "Epoch 21/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0603 - accuracy: 0.9752\n",
      "Epoch 22/100\n",
      "4232/4232 [==============================] - 32s 7ms/step - loss: 0.0556 - accuracy: 0.9780\n",
      "Epoch 23/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0542 - accuracy: 0.9779\n",
      "Epoch 24/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0562 - accuracy: 0.9767\n",
      "Epoch 25/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0534 - accuracy: 0.9761\n",
      "Epoch 26/100\n",
      "4232/4232 [==============================] - 32s 7ms/step - loss: 0.0498 - accuracy: 0.9770\n",
      "Epoch 27/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0479 - accuracy: 0.9797\n",
      "Epoch 28/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0475 - accuracy: 0.9784\n",
      "Epoch 29/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0469 - accuracy: 0.9790\n",
      "Epoch 30/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0583 - accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0569 - accuracy: 0.9753\n",
      "Epoch 32/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0476 - accuracy: 0.9792\n",
      "Epoch 33/100\n",
      "4232/4232 [==============================] - 34s 8ms/step - loss: 0.0441 - accuracy: 0.9802\n",
      "Epoch 34/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0427 - accuracy: 0.9805\n",
      "Epoch 35/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0411 - accuracy: 0.9800\n",
      "Epoch 36/100\n",
      "4232/4232 [==============================] - 34s 8ms/step - loss: 0.0413 - accuracy: 0.9806\n",
      "Epoch 37/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0391 - accuracy: 0.9811\n",
      "Epoch 38/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0390 - accuracy: 0.9805\n",
      "Epoch 39/100\n",
      "4232/4232 [==============================] - 26s 6ms/step - loss: 0.0384 - accuracy: 0.9819\n",
      "Epoch 40/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0438 - accuracy: 0.9805\n",
      "Epoch 41/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0455 - accuracy: 0.9787\n",
      "Epoch 42/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0413 - accuracy: 0.9822\n",
      "Epoch 43/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0397 - accuracy: 0.9809\n",
      "Epoch 44/100\n",
      "4232/4232 [==============================] - 32s 8ms/step - loss: 0.0376 - accuracy: 0.9815\n",
      "Epoch 45/100\n",
      "4232/4232 [==============================] - 32s 7ms/step - loss: 0.0374 - accuracy: 0.9815\n",
      "Epoch 46/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0374 - accuracy: 0.9816\n",
      "Epoch 47/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0362 - accuracy: 0.9826\n",
      "Epoch 48/100\n",
      "4232/4232 [==============================] - 25s 6ms/step - loss: 0.0363 - accuracy: 0.9812\n",
      "Epoch 49/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0357 - accuracy: 0.9817\n",
      "Epoch 50/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0365 - accuracy: 0.9825\n",
      "Epoch 51/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0480 - accuracy: 0.9797\n",
      "Epoch 52/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0479 - accuracy: 0.9784\n",
      "Epoch 53/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0409 - accuracy: 0.9804\n",
      "Epoch 54/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0376 - accuracy: 0.9824\n",
      "Epoch 55/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0343 - accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0346 - accuracy: 0.9828\n",
      "Epoch 57/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0331 - accuracy: 0.9831\n",
      "Epoch 58/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0326 - accuracy: 0.9828\n",
      "Epoch 59/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0341 - accuracy: 0.9823\n",
      "Epoch 60/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0333 - accuracy: 0.9835\n",
      "Epoch 61/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0337 - accuracy: 0.9831\n",
      "Epoch 62/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0329 - accuracy: 0.9829\n",
      "Epoch 63/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0320 - accuracy: 0.9835\n",
      "Epoch 64/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0316 - accuracy: 0.9841\n",
      "Epoch 65/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0330 - accuracy: 0.9830\n",
      "Epoch 66/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0317 - accuracy: 0.9836\n",
      "Epoch 67/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0319 - accuracy: 0.9837\n",
      "Epoch 68/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0312 - accuracy: 0.9831\n",
      "Epoch 69/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0322 - accuracy: 0.9815\n",
      "Epoch 70/100\n",
      "4232/4232 [==============================] - 32s 7ms/step - loss: 0.0297 - accuracy: 0.9847\n",
      "Epoch 71/100\n",
      "4232/4232 [==============================] - 26s 6ms/step - loss: 0.0306 - accuracy: 0.9840\n",
      "Epoch 72/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0412 - accuracy: 0.9807\n",
      "Epoch 73/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0403 - accuracy: 0.9814\n",
      "Epoch 74/100\n",
      "4232/4232 [==============================] - 33s 8ms/step - loss: 0.0359 - accuracy: 0.9830\n",
      "Epoch 75/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0317 - accuracy: 0.9835\n",
      "Epoch 76/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0309 - accuracy: 0.9843\n",
      "Epoch 77/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0300 - accuracy: 0.9838\n",
      "Epoch 78/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0304 - accuracy: 0.9847\n",
      "Epoch 79/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0363 - accuracy: 0.9836\n",
      "Epoch 80/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0314 - accuracy: 0.9850\n",
      "Epoch 81/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0330 - accuracy: 0.9825\n",
      "Epoch 82/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0305 - accuracy: 0.9842\n",
      "Epoch 83/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0302 - accuracy: 0.9842\n",
      "Epoch 84/100\n",
      "4232/4232 [==============================] - 26s 6ms/step - loss: 0.0296 - accuracy: 0.9844\n",
      "Epoch 85/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0290 - accuracy: 0.9839\n",
      "Epoch 86/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0300 - accuracy: 0.9850\n",
      "Epoch 87/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0305 - accuracy: 0.9840\n",
      "Epoch 88/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0298 - accuracy: 0.9844\n",
      "Epoch 89/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0322 - accuracy: 0.9844\n",
      "Epoch 90/100\n",
      "4232/4232 [==============================] - 27s 6ms/step - loss: 0.0293 - accuracy: 0.9849\n",
      "Epoch 91/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0294 - accuracy: 0.9851\n",
      "Epoch 92/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0298 - accuracy: 0.9840\n",
      "Epoch 93/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0285 - accuracy: 0.9856\n",
      "Epoch 94/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0291 - accuracy: 0.9839\n",
      "Epoch 95/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0288 - accuracy: 0.9854\n",
      "Epoch 96/100\n",
      "4232/4232 [==============================] - 31s 7ms/step - loss: 0.0290 - accuracy: 0.9849\n",
      "Epoch 97/100\n",
      "4232/4232 [==============================] - 32s 7ms/step - loss: 0.0284 - accuracy: 0.9848\n",
      "Epoch 98/100\n",
      "4232/4232 [==============================] - 30s 7ms/step - loss: 0.0270 - accuracy: 0.9860\n",
      "Epoch 99/100\n",
      "4232/4232 [==============================] - 29s 7ms/step - loss: 0.0284 - accuracy: 0.9857\n",
      "Epoch 100/100\n",
      "4232/4232 [==============================] - 28s 7ms/step - loss: 0.0295 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x270c847b848>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=100,\n",
    "#           validation_data=[x_test, y_test]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "747/747 [==============================] - 1s 2ms/step\n",
      "Test set\n",
      "  Loss: 2.017\n",
      "  Accuracy: 73.315 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "accr = model.evaluate(x_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f} %'.format(accr[0],accr[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_pred[0],0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_max = [np.round(p,0).astype(int) for p in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_max[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: Classification Report\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65       276\n",
      "           1       0.49      0.58      0.53       193\n",
      "           2       0.62      0.58      0.60       278\n",
      "\n",
      "   micro avg       0.60      0.60      0.60       747\n",
      "   macro avg       0.60      0.59      0.59       747\n",
      "weighted avg       0.61      0.60      0.60       747\n",
      " samples avg       0.59      0.60      0.59       747\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\konark\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print (\":: Classification Report\")\n",
    "print (\"\")\n",
    "print (classification_report(y_test, y_pred_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
